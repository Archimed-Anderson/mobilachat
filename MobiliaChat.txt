Prompt Complet pour Cursor - Chatbot SAV Free Mobile(MobiliaChat)

# CONTEXTE DU PROJET


Je développe un chatbot SAV(MobiliaChat) intelligent pour Free Mobile en local avec Cursor. L'application combine :
- Interface Streamlit pour le frontend
- API FastAPI pour le backend
- Moteur IA avec RAG (ChromaDB + Transformers)
- Surveillance Mastodon pour les réclamations clients
- Système de ticketing intégré
- Déploiement sur PostgreSQL local + Supabase (cloud)
_ Entraînement du modèle sur des datasets SAV personnalisés (FAQ, procédures internes, historiques de tickets)


# OBJECTIFS PRINCIPAUX


1. **Chatbot IA intelligent** :
   - Réponses automatiques basées sur la documentation Free Mobile
   - Intégration avec ChromaDB pour la recherche sémantique et contextuelle dans les documents
_ Utilisation d’un moteur RAG (Retrieval-Augmented Generation) pour générer des réponses contextuelles
   - Entraînement sur datasets SAV personnalisés
   - Liens vers ressources Free Mobile
- 


2. **Intégration Mastodon** :
   - Surveillance temps réel des mentions #Free, #FreeMobile
   - Détection automatique des réclamations
   - Génération de liens de contact uniques
   - Réponses automatiques publiques


3. **Formulaire de contact intelligent** :
   - Capture nom, prénom, numéro de téléphone
   - Création automatique de tickets
   - Redirection vers chat avec contexte préservé


4. **Analytics & Monitoring** :
   - Dashboard temps réel avec Plotly
   - Suivi des conversations et tickets
   - Métriques de performance du chatbot


# STACK TECHNIQUE
Frontend:        Streamlit 1.28+
Backend API:     FastAPI 0.104+
Base de données: PostgreSQL (local) + Supabase (cloud)
Cache:           Redis
IA/LLM:          Transformers + Sentence-Transformers
Vector Store:    ChromaDB
Social:          Mastodon.py
Container:       Docker + Docker Compose


# STRUCTURE DES DOSSIERS


Créer cette structure exacte :
chatbot-free-mobile/
│
├── .github/
│   └── workflows/
│       ├── ci.yml
│       └── deploy.yml
│
├── apps/
│   ├── frontend/              # Streamlit
│   ├── backend/               # FastAPI
│   ├── ai-engine/             # Moteur IA + RAG
│   └── social-monitor/        # Surveillance Mastodon
│
├── data/
│   ├── raw/
│   │   ├── faqs/
│   │   ├── conversations/
│   │   └── documentation/
│   ├── processed/
│   ├── vector_store/
│   └── scripts/
│
├── shared/
│   ├── types/
│   ├── utils/
│   ├── constants/
│   └── config/
│
├── infrastructure/
│   └── docker/
│
├── tests/
├── docs/
└── scripts/


# PARTIE 1 : CONFIGURATION INITIALE


## 1.1 Fichier .env.example


Créer à la racine du projet :
```bash
# ============================================
# BASES DE DONNÉES
# ============================================
POSTGRES_LOCAL_HOST=localhost
POSTGRES_LOCAL_PORT=5432
POSTGRES_LOCAL_USER=chatbot_user
POSTGRES_LOCAL_PASSWORD=SecurePassword123!
POSTGRES_LOCAL_DB=chatbot_free_mobile


SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_KEY=your_service_key
SUPABASE_DB_URL=postgresql://postgres:password@db.your-project.supabase.co:5432/postgres


REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0


# ============================================
# MASTODON
# ============================================
MASTODON_INSTANCE_URL=https://mastodon.social
MASTODON_CLIENT_ID=
MASTODON_CLIENT_SECRET=
MASTODON_ACCESS_TOKEN=
MASTODON_MONITOR_HASHTAGS=Free,FreeMobile,SAVFree


# ============================================
# IA CONFIGURATION
# ============================================
LLM_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=512
LLM_DEVICE=cpu


EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
VECTOR_STORE_PATH=./data/vector_store
VECTOR_STORE_COLLECTION=free_mobile_knowledge


# ============================================
# URLS DES SERVICES
# ============================================
FRONTEND_URL=http://localhost:8501
BACKEND_API_URL=http://localhost:8000
AI_ENGINE_URL=http://localhost:8001
SOCIAL_MONITOR_URL=http://localhost:8002


# ============================================
# SÉCURITÉ
# ============================================
SECRET_KEY=your-secret-key-min-32-characters-change-in-production
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30


# ============================================
# FREE MOBILE LINKS
# ============================================
FREE_MOBILE_FAQ_URL=https://mobile.free.fr/assistance/
FREE_MOBILE_ESPACE_CLIENT_URL=https://mobile.free.fr/moncompte/
FREE_MOBILE_CONTACT_URL=https://mobile.free.fr/assistance/contact.html
1.2 Requirements.txt Global
Créer requirements.txt à la racine :
txt
# Core
streamlit==1.28.1
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-dotenv==1.0.0


# Database
sqlalchemy==2.0.23
psycopg2-binary==2.9.9
alembic==1.12.1
supabase==2.0.3


# Redis
redis==5.0.1


# IA & NLP
transformers==4.35.2
torch==2.1.1
sentence-transformers==2.2.2
chromadb==0.4.18
langchain==0.0.340
langchain-community==0.0.10


# Mastodon
Mastodon.py==1.8.1


# Utilities
pydantic==2.5.0
pydantic-settings==2.1.0
python-multipart==0.0.6
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
httpx==0.25.2
aiohttp==3.9.1


# Data Processing
pandas==2.1.3
numpy==1.26.2
plotly==5.18.0


# Streamlit Components
streamlit-option-menu==0.3.6
streamlit-chat==0.1.1
streamlit-authenticator==0.2.3


# Testing
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
PARTIE 2 : BACKEND FASTAPI
2.1 Structure apps/backend/
apps/backend/
├── api/
│   └── v1/
│       ├── __init__.py
│       └── routes/
│           ├── __init__.py
│           ├── chat.py
│           ├── tickets.py
│           ├── users.py
│           ├── analytics.py
│           └── mastodon.py
├── core/
│   ├── __init__.py
│   ├── config.py
│   ├── security.py
│   ├── database.py
│   └── redis_client.py
├── models/
│   ├── __init__.py
│   ├── user.py
│   ├── conversation.py
│   ├── message.py
│   ├── ticket.py
│   └── mastodon_post.py
├── schemas/
│   ├── __init__.py
│   ├── chat.py
│   ├── ticket.py
│   └── user.py
├── services/
│   ├── __init__.py
│   ├── chat_service.py
│   ├── ticket_service.py
│   ├── analytics_service.py
│   └── notification_service.py
├── main.py
├── requirements.txt
└── Dockerfile
2.2 Fichier apps/backend/core/config.py
python
from pydantic_settings import BaseSettings
from typing import Optional
import os
from dotenv import load_dotenv


load_dotenv()


class Settings(BaseSettings):
    # Application
    APP_NAME: str = "Free Mobile Chatbot API"
    VERSION: str = "1.0.0"
    DEBUG: bool = os.getenv("DEBUG", "false").lower() == "true"
    
    # Database
    USE_SUPABASE: bool = os.getenv("USE_SUPABASE", "false").lower() == "true"
    
    # PostgreSQL Local
    POSTGRES_LOCAL_HOST: str = os.getenv("POSTGRES_LOCAL_HOST", "localhost")
    POSTGRES_LOCAL_PORT: int = int(os.getenv("POSTGRES_LOCAL_PORT", 5432))
    POSTGRES_LOCAL_USER: str = os.getenv("POSTGRES_LOCAL_USER", "chatbot_user")
    POSTGRES_LOCAL_PASSWORD: str = os.getenv("POSTGRES_LOCAL_PASSWORD", "")
    POSTGRES_LOCAL_DB: str = os.getenv("POSTGRES_LOCAL_DB", "chatbot_free_mobile")
    
    # Supabase
    SUPABASE_URL: Optional[str] = os.getenv("SUPABASE_URL")
    SUPABASE_ANON_KEY: Optional[str] = os.getenv("SUPABASE_ANON_KEY")
    SUPABASE_SERVICE_KEY: Optional[str] = os.getenv("SUPABASE_SERVICE_KEY")
    SUPABASE_DB_URL: Optional[str] = os.getenv("SUPABASE_DB_URL")
    
    # Redis
    REDIS_HOST: str = os.getenv("REDIS_HOST", "localhost")
    REDIS_PORT: int = int(os.getenv("REDIS_PORT", 6379))
    REDIS_PASSWORD: Optional[str] = os.getenv("REDIS_PASSWORD")
    REDIS_DB: int = int(os.getenv("REDIS_DB", 0))
    
    # Security
    SECRET_KEY: str = os.getenv("SECRET_KEY", "your-secret-key-change-in-production")
    JWT_ALGORITHM: str = os.getenv("JWT_ALGORITHM", "HS256")
    ACCESS_TOKEN_EXPIRE_MINUTES: int = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", 30))
    
    # Services URLs
    AI_ENGINE_URL: str = os.getenv("AI_ENGINE_URL", "http://localhost:8001")
    FRONTEND_URL: str = os.getenv("FRONTEND_URL", "http://localhost:8501")
    
    # Free Mobile Links
    FREE_MOBILE_FAQ_URL: str = os.getenv("FREE_MOBILE_FAQ_URL", "https://mobile.free.fr/assistance/")
    FREE_MOBILE_ESPACE_CLIENT_URL: str = os.getenv("FREE_MOBILE_ESPACE_CLIENT_URL", "https://mobile.free.fr/moncompte/")
    FREE_MOBILE_CONTACT_URL: str = os.getenv("FREE_MOBILE_CONTACT_URL", "https://mobile.free.fr/assistance/contact.html")
    
    @property
    def DATABASE_URL(self) -> str:
        """Retourne l'URL de la base de données selon la configuration"""
        if self.USE_SUPABASE and self.SUPABASE_DB_URL:
            return self.SUPABASE_DB_URL
        else:
            return (
                f"postgresql://{self.POSTGRES_LOCAL_USER}:{self.POSTGRES_LOCAL_PASSWORD}"
                f"@{self.POSTGRES_LOCAL_HOST}:{self.POSTGRES_LOCAL_PORT}/{self.POSTGRES_LOCAL_DB}"
            )
    
    @property
    def REDIS_URL(self) -> str:
        """Retourne l'URL Redis"""
        if self.REDIS_PASSWORD:
            return f"redis://:{self.REDIS_PASSWORD}@{self.REDIS_HOST}:{self.REDIS_PORT}/{self.REDIS_DB}"
        return f"redis://{self.REDIS_HOST}:{self.REDIS_PORT}/{self.REDIS_DB}"
    
    class Config:
        env_file = ".env"
        case_sensitive = True


settings = Settings()
2.3 Fichier apps/backend/core/database.py
python
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from .config import settings


# Créer l'engine de base de données
engine = create_engine(
    settings.DATABASE_URL,
    pool_pre_ping=True,
    pool_size=10,
    max_overflow=20,
    echo=settings.DEBUG
)


# Session locale
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


# Base pour les modèles
Base = declarative_base()


# Dependency pour obtenir la DB session
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
2.4 Fichier apps/backend/core/redis_client.py
python
import redis.asyncio as redis
from typing import Optional
import json
from .config import settings


class RedisClient:
    def __init__(self):
        self.redis: Optional[redis.Redis] = None
    
    async def connect(self):
        """Connexion à Redis"""
        self.redis = await redis.from_url(
            settings.REDIS_URL,
            encoding="utf-8",
            decode_responses=True
        )
    
    async def disconnect(self):
        """Déconnexion de Redis"""
        if self.redis:
            await self.redis.close()
    
    async def set_value(self, key: str, value: any, expire: int = 3600):
        """Stocke une valeur avec expiration optionnelle"""
        if isinstance(value, (dict, list)):
            value = json.dumps(value)
        await self.redis.set(key, value, ex=expire)
    
    async def get_value(self, key: str) -> Optional[str]:
        """Récupère une valeur"""
        value = await self.redis.get(key)
        if value:
            try:
                return json.loads(value)
            except json.JSONDecodeError:
                return value
        return None
    
    async def delete_value(self, key: str):
        """Supprime une valeur"""
        await self.redis.delete(key)
    
    async def set_context(self, token: str, context: dict, expire: int = 86400):
        """Stocke un contexte de conversation (24h par défaut)"""
        await self.set_value(f"context:{token}", context, expire)
    
    async def get_context(self, token: str) -> Optional[dict]:
        """Récupère un contexte de conversation"""
        return await self.get_value(f"context:{token}")


# Instance globale
redis_client = RedisClient()
2.5 Fichier apps/backend/models/conversation.py
python
from sqlalchemy import Column, String, DateTime, ForeignKey, Text, Boolean
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
from datetime import datetime
import uuid
from ..core.database import Base


class Conversation(Base):
    __tablename__ = "conversations"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    user_id = Column(UUID(as_uuid=True), ForeignKey("users.id", ondelete="CASCADE"), nullable=True)
    source = Column(String(50), default="web")  # web, mastodon
    status = Column(String(50), default="active")  # active, closed, escalated
    mastodon_user = Column(String(255), nullable=True)
    mastodon_post_id = Column(String(255), nullable=True)
    context_token = Column(String(255), unique=True, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # Relations
    messages = relationship("Message", back_populates="conversation", cascade="all, delete-orphan")
    tickets = relationship("Ticket", back_populates="conversation", cascade="all, delete-orphan")
    user = relationship("User", back_populates="conversations")


class Message(Base):
    __tablename__ = "messages"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    conversation_id = Column(UUID(as_uuid=True), ForeignKey("conversations.id", ondelete="CASCADE"))
    role = Column(String(50), nullable=False)  # user, assistant, system
    content = Column(Text, nullable=False)
    metadata = Column(Text, nullable=True)  # JSON stocké en texte
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relations
    conversation = relationship("Conversation", back_populates="messages")
2.6 Fichier apps/backend/models/ticket.py
python
from sqlalchemy import Column, String, DateTime, ForeignKey, Text
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
from datetime import datetime
import uuid
from ..core.database import Base


class Ticket(Base):
    __tablename__ = "tickets"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    conversation_id = Column(UUID(as_uuid=True), ForeignKey("conversations.id", ondelete="CASCADE"))
    priority = Column(String(50), default="MEDIUM")  # LOW, MEDIUM, HIGH, URGENT
    status = Column(String(50), default="OPEN")  # OPEN, IN_PROGRESS, RESOLVED, CLOSED
    category = Column(String(100), nullable=True)  # facturation, technique, forfait
    assigned_to = Column(UUID(as_uuid=True), ForeignKey("users.id"), nullable=True)
    resolution_notes = Column(Text, nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    resolved_at = Column(DateTime, nullable=True)
    
    # Relations
    conversation = relationship("Conversation", back_populates="tickets")
    assigned_user = relationship("User", foreign_keys=[assigned_to])
2.7 Fichier apps/backend/models/user.py
python
from sqlalchemy import Column, String, DateTime, Boolean
from sqlalchemy.dialects.postgresql import UUID
from sqlalchemy.orm import relationship
from datetime import datetime
import uuid
from ..core.database import Base


class User(Base):
    __tablename__ = "users"
    
    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)
    username = Column(String(255), unique=True, nullable=False)
    email = Column(String(255), unique=True, nullable=False)
    hashed_password = Column(String(255), nullable=False)
    full_name = Column(String(255), nullable=True)
    phone_number = Column(String(20), nullable=True)
    is_active = Column(Boolean, default=True)
    is_superuser = Column(Boolean, default=False)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # Relations
    conversations = relationship("Conversation", back_populates="user")
2.8 Fichier apps/backend/schemas/chat.py
python
from pydantic import BaseModel, Field
from typing import Optional, List
from datetime import datetime
from uuid import UUID


class MessageCreate(BaseModel):
    content: str = Field(..., min_length=1, max_length=5000)
    conversation_id: Optional[UUID] = None


class MessageResponse(BaseModel):
    id: UUID
    conversation_id: UUID
    role: str
    content: str
    created_at: datetime
    
    class Config:
        from_attributes = True


class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1)
    conversation_id: Optional[UUID] = None
    context_token: Optional[str] = None
    user_info: Optional[dict] = None


class ChatResponse(BaseModel):
    conversation_id: UUID
    message: MessageResponse
    response: MessageResponse
    needs_escalation: bool = False
    suggested_links: Optional[List[dict]] = None


class ConversationCreate(BaseModel):
    source: str = "web"
    context_token: Optional[str] = None
    mastodon_user: Optional[str] = None
    mastodon_post_id: Optional[str] = None


class ConversationResponse(BaseModel):
    id: UUID
    source: str
    status: str
    created_at: datetime
    message_count: int = 0
    
    class Config:
        from_attributes = True
2.9 Fichier apps/backend/api/v1/routes/chat.py
python
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session
from typing import List
import httpx
from uuid import UUID


from ....core.database import get_db
from ....core.redis_client import redis_client
from ....core.config import settings
from ....schemas.chat import ChatRequest, ChatResponse, MessageResponse
from ....services.chat_service import ChatService
from ....services.ticket_service import TicketService


router = APIRouter(prefix="/chat", tags=["chat"])


@router.post("/message", response_model=ChatResponse)
async def send_message(
    request: ChatRequest,
    db: Session = Depends(get_db)
):
    """
    Envoie un message et obtient une réponse du chatbot
    """
    try:
        chat_service = ChatService(db)
        
        # Récupérer ou créer la conversation
        conversation = await chat_service.get_or_create_conversation(
            conversation_id=request.conversation_id,
            context_token=request.context_token,
            user_info=request.user_info
        )
        
        # Sauvegarder le message utilisateur
        user_message = await chat_service.save_message(
            conversation_id=conversation.id,
            role="user",
            content=request.message
        )
        
        # Obtenir la réponse de l'IA
        ai_response = await chat_service.get_ai_response(
            message=request.message,
            conversation_id=conversation.id
        )
        
        # Sauvegarder la réponse de l'assistant
        assistant_message = await chat_service.save_message(
            conversation_id=conversation.id,
            role="assistant",
            content=ai_response["response"]
        )
        
        # Vérifier si escalade nécessaire
        needs_escalation = ai_response.get("needs_escalation", False)
        
        if needs_escalation:
            ticket_service = TicketService(db)
            await ticket_service.create_ticket(
                conversation_id=conversation.id,
                priority="HIGH",
                category=ai_response.get("category", "general")
            )
        
        # Préparer les liens suggérés
        suggested_links = [
            {
                "title": "FAQ Free Mobile",
                "url": settings.FREE_MOBILE_FAQ_URL,
                "description": "Consultez notre aide en ligne"
            },
            {
                "title": "Espace Client",
                "url": settings.FREE_MOBILE_ESPACE_CLIENT_URL,
                "description": "Gérez votre compte"
            }
        ]
        
        return ChatResponse(
            conversation_id=conversation.id,
            message=MessageResponse.from_orm(user_message),
            response=MessageResponse.from_orm(assistant_message),
            needs_escalation=needs_escalation,
            suggested_links=suggested_links
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors du traitement du message: {str(e)}"
        )


@router.get("/conversation/{conversation_id}/messages", response_model=List[MessageResponse])
async def get_conversation_messages(
    conversation_id: UUID,
    db: Session = Depends(get_db)
):
    """
    Récupère tous les messages d'une conversation
    """
    chat_service = ChatService(db)
    messages = await chat_service.get_conversation_messages(conversation_id)
    return [MessageResponse.from_orm(msg) for msg in messages]
2.10 Fichier apps/backend/services/chat_service.py
python
from sqlalchemy.orm import Session
from sqlalchemy import desc
from typing import Optional, List, Dict, Any
from uuid import UUID
import httpx
import hashlib
from datetime import datetime


from ..models.conversation import Conversation, Message
from ..models.user import User
from ..core.config import settings
from ..core.redis_client import redis_client


class ChatService:
    def __init__(self, db: Session):
        self.db = db
    
    async def get_or_create_conversation(
        self,
        conversation_id: Optional[UUID] = None,
        context_token: Optional[str] = None,
        user_info: Optional[dict] = None
    ) -> Conversation:
        """
        Récupère ou crée une conversation
        """
        # Si conversation_id fourni, récupérer la conversation existante
        if conversation_id:
            conversation = self.db.query(Conversation).filter(
                Conversation.id == conversation_id
            ).first()
            if conversation:
                return conversation
        
        # Si context_token fourni, récupérer depuis Redis et créer conversation
        if context_token:
            context = await redis_client.get_context(context_token)
            if context:
                conversation = Conversation(
                    source=context.get("source", "web"),
                    context_token=context_token,
                    mastodon_user=context.get("mastodon_user"),
                    mastodon_post_id=context.get("mastodon_id")
                )
                self.db.add(conversation)
                self.db.commit()
                self.db.refresh(conversation)
                return conversation
        
        # Créer une nouvelle conversation
        conversation = Conversation(source="web")
        
        # Si user_info fourni, créer/récupérer l'utilisateur
        if user_info:
            user = await self._get_or_create_user(user_info)
            conversation.user_id = user.id
        
        self.db.add(conversation)
        self.db.commit()
        self.db.refresh(conversation)
        
        return conversation
    
    async def _get_or_create_user(self, user_info: dict) -> User:
        """
        Récupère ou crée un utilisateur
        """
        email = user_info.get("email")
        
        if email:
            user = self.db.query(User).filter(User.email == email).first()
            if user:
                return user
        
        # Créer un nouvel utilisateur
        username = user_info.get("email", f"user_{hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8]}")
        
        user = User(
            username=username,
            email=user_info.get("email", f"{username}@temp.local"),
            hashed_password="",  # Pas de mot de passe pour les utilisateurs anonymes
            full_name=user_info.get("full_name"),
            phone_number=user_info.get("phone_number"),
            is_active=True
        )
        
        self.db.add(user)
        self.db.commit()
        self.db.refresh(user)
        
        return user
    
    async def save_message(
        self,
        conversation_id: UUID,
        role: str,
        content: str,
        metadata: Optional[dict] = None
    ) -> Message:
        """
        Sauvegarde un message dans la base de données
        """
        import json
        
        message = Message(
            conversation_id=conversation_id,
            role=role,
            content=content,
            metadata=json.dumps(metadata) if metadata else None
        )
        
        self.db.add(message)
        self.db.commit()
        self.db.refresh(message)
        
        return message
    
    async def get_conversation_messages(
        self,
        conversation_id: UUID,
        limit: int = 50
    ) -> List[Message]:
        """
        Récupère les messages d'une conversation
        """
        messages = self.db.query(Message).filter(
            Message.conversation_id == conversation_id
        ).order_by(Message.created_at).limit(limit).all()
        
        return messages
    
    async def get_ai_response(
        self,
        message: str,
        conversation_id: UUID
    ) -> Dict[str, Any]:
        """
        Appelle l'API IA pour obtenir une réponse
        """
        # Récupérer l'historique de conversation
        messages = await self.get_conversation_messages(conversation_id)
        
        # Préparer le contexte
        conversation_history = [
            {"role": msg.role, "content": msg.content}
            for msg in messages[-10:]  # Garder les 10 derniers messages
        ]
        
        # Appeler l'API IA
        async with httpx.AsyncClient(timeout=30.0) as client:
            try:
                response = await client.post(
                    f"{settings.AI_ENGINE_URL}/api/generate",
                    json={
                        "message": message,
                        "conversation_history": conversation_history,
                        "conversation_id": str(conversation_id)
                    }
                )
                response.raise_for_status()
                return response.json()
            except httpx.HTTPError as e:
                # Fallback en cas d'erreur
                return {
                    "response": "Je suis désolé, je rencontre une difficulté technique. Un conseiller va prendre en charge votre demande.",
                    "needs_escalation": True,
                    "confidence": 0.0
                }
PARTIE 3 : AI ENGINE (RAG + LLM)
3.1 Structure apps/ai-engine/
apps/ai-engine/
├── models/
│   ├── __init__.py
│   ├── llm_manager.py
│   ├── embeddings.py
│   └── response_generator.py
├── rag/
│   ├── __init__.py
│   ├── vector_store.py
│   ├── document_processor.py
│   └── retriever.py
├── utils/
│   ├── __init__.py
│   ├── intent_detector.py
│   ├── sentiment_analyzer.py
│   └── entity_extractor.py
├── config/
│   ├── __init__.py
│
Continuer
python
│   └── settings.py
├── api.py
├── requirements.txt
└── Dockerfile
3.2 Fichier apps/ai-engine/config/settings.py
python
from pydantic_settings import BaseSettings
from typing import Optional
import os
from dotenv import load_dotenv


load_dotenv()


class AISettings(BaseSettings):
    # Modèle LLM
    LLM_MODEL_NAME: str = os.getenv("LLM_MODEL_NAME", "mistralai/Mistral-7B-Instruct-v0.2")
    LLM_TEMPERATURE: float = float(os.getenv("LLM_TEMPERATURE", "0.7"))
    LLM_MAX_TOKENS: int = int(os.getenv("LLM_MAX_TOKENS", "512"))
    LLM_DEVICE: str = os.getenv("LLM_DEVICE", "cpu")
    
    # Embeddings
    EMBEDDING_MODEL: str = os.getenv("EMBEDDING_MODEL", "sentence-transformers/all-MiniLM-L6-v2")
    
    # Vector Store
    VECTOR_STORE_PATH: str = os.getenv("VECTOR_STORE_PATH", "./data/vector_store")
    VECTOR_STORE_COLLECTION: str = os.getenv("VECTOR_STORE_COLLECTION", "free_mobile_knowledge")
    
    # RAG Configuration
    RAG_TOP_K: int = 5
    RAG_SIMILARITY_THRESHOLD: float = 0.7
    
    # Free Mobile Links
    FREE_MOBILE_FAQ_URL: str = os.getenv("FREE_MOBILE_FAQ_URL", "https://mobile.free.fr/assistance/")
    FREE_MOBILE_ESPACE_CLIENT_URL: str = os.getenv("FREE_MOBILE_ESPACE_CLIENT_URL", "https://mobile.free.fr/moncompte/")
    
    class Config:
        env_file = ".env"


ai_settings = AISettings()
3.3 Fichier apps/ai-engine/rag/vector_store.py
python
import chromadb
from chromadb.config import Settings
from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer
import os


from ..config.settings import ai_settings


class VectorStore:
    def __init__(self):
        self.client = chromadb.Client(Settings(
            chroma_db_impl="duckdb+parquet",
            persist_directory=ai_settings.VECTOR_STORE_PATH
        ))
        
        self.embedding_model = SentenceTransformer(ai_settings.EMBEDDING_MODEL)
        
        # Créer ou récupérer la collection
        self.collection = self.client.get_or_create_collection(
            name=ai_settings.VECTOR_STORE_COLLECTION,
            metadata={"description": "Base de connaissances Free Mobile"}
        )
    
    def add_documents(
        self,
        documents: List[str],
        metadatas: List[Dict[str, Any]],
        ids: Optional[List[str]] = None
    ):
        """
        Ajoute des documents à la base vectorielle
        """
        if ids is None:
            import uuid
            ids = [str(uuid.uuid4()) for _ in documents]
        
        # Générer les embeddings
        embeddings = self.embedding_model.encode(documents).tolist()
        
        # Ajouter à la collection
        self.collection.add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
    
    def search(
        self,
        query: str,
        top_k: int = None,
        filter_metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Recherche des documents similaires
        """
        if top_k is None:
            top_k = ai_settings.RAG_TOP_K
        
        # Générer l'embedding de la requête
        query_embedding = self.embedding_model.encode([query]).tolist()
        
        # Rechercher
        results = self.collection.query(
            query_embeddings=query_embedding,
            n_results=top_k,
            where=filter_metadata
        )
        
        return results
    
    def get_relevant_context(
        self,
        query: str,
        top_k: int = None
    ) -> List[Dict[str, Any]]:
        """
        Récupère le contexte pertinent pour une requête
        """
        results = self.search(query, top_k)
        
        contexts = []
        if results and results['documents']:
            for i, doc in enumerate(results['documents'][0]):
                distance = results['distances'][0][i]
                similarity = 1 - distance  # Convertir distance en similarité
                
                # Filtrer par seuil de similarité
                if similarity >= ai_settings.RAG_SIMILARITY_THRESHOLD:
                    contexts.append({
                        'content': doc,
                        'metadata': results['metadatas'][0][i],
                        'similarity': similarity
                    })
        
        return contexts
    
    def delete_collection(self):
        """Supprime la collection"""
        self.client.delete_collection(name=ai_settings.VECTOR_STORE_COLLECTION)
    
    def get_collection_count(self) -> int:
        """Retourne le nombre de documents dans la collection"""
        return self.collection.count()
3.4 Fichier apps/ai-engine/rag/document_processor.py
python
import os
import json
from typing import List, Dict, Any
import PyPDF2
from pathlib import Path


class DocumentProcessor:
    def __init__(self, data_path: str = "./data/raw"):
        self.data_path = Path(data_path)
    
    def process_faqs(self) -> List[Dict[str, Any]]:
        """
        Traite les fichiers FAQ JSON
        """
        documents = []
        faq_path = self.data_path / "faqs"
        
        if not faq_path.exists():
            return documents
        
        for faq_file in faq_path.glob("*.json"):
            with open(faq_file, 'r', encoding='utf-8') as f:
                faq_data = json.load(f)
                
                category = faq_file.stem  # facturation, technique, etc.
                
                for item in faq_data:
                    # Combiner question et réponse pour le document
                    doc_content = f"Question: {item['question']}\nRéponse: {item['answer']}"
                    
                    documents.append({
                        'content': doc_content,
                        'metadata': {
                            'type': 'faq',
                            'category': category,
                            'question': item['question'],
                            'source': str(faq_file)
                        }
                    })
        
        return documents
    
    def process_pdf(self, pdf_path: str) -> List[Dict[str, Any]]:
        """
        Traite un fichier PDF et le découpe en chunks
        """
        documents = []
        
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            
            for page_num, page in enumerate(pdf_reader.pages):
                text = page.extract_text()
                
                # Découper en chunks (paragraphes)
                chunks = self._split_into_chunks(text, chunk_size=500)
                
                for i, chunk in enumerate(chunks):
                    documents.append({
                        'content': chunk,
                        'metadata': {
                            'type': 'documentation',
                            'source': os.path.basename(pdf_path),
                            'page': page_num + 1,
                            'chunk': i
                        }
                    })
        
        return documents
    
    def process_markdown(self, md_path: str) -> List[Dict[str, Any]]:
        """
        Traite un fichier Markdown
        """
        documents = []
        
        with open(md_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
            # Découper par sections (titres)
            sections = self._split_markdown_by_headers(content)
            
            for section in sections:
                documents.append({
                    'content': section['content'],
                    'metadata': {
                        'type': 'documentation',
                        'source': os.path.basename(md_path),
                        'section': section['title']
                    }
                })
        
        return documents
    
    def _split_into_chunks(
        self,
        text: str,
        chunk_size: int = 500,
        overlap: int = 50
    ) -> List[str]:
        """
        Découpe un texte en chunks avec chevauchement
        """
        words = text.split()
        chunks = []
        
        for i in range(0, len(words), chunk_size - overlap):
            chunk = ' '.join(words[i:i + chunk_size])
            if chunk.strip():
                chunks.append(chunk)
        
        return chunks
    
    def _split_markdown_by_headers(self, content: str) -> List[Dict[str, str]]:
        """
        Découpe un Markdown par sections (headers)
        """
        sections = []
        current_section = {'title': 'Introduction', 'content': ''}
        
        for line in content.split('\n'):
            if line.startswith('#'):
                # Nouvelle section
                if current_section['content'].strip():
                    sections.append(current_section)
                
                title = line.lstrip('#').strip()
                current_section = {'title': title, 'content': ''}
            else:
                current_section['content'] += line + '\n'
        
        # Ajouter la dernière section
        if current_section['content'].strip():
            sections.append(current_section)
        
        return sections
    
    def process_all_documents(self) -> List[Dict[str, Any]]:
        """
        Traite tous les documents disponibles
        """
        all_documents = []
        
        # Traiter les FAQs
        all_documents.extend(self.process_faqs())
        
        # Traiter les PDFs
        pdf_path = self.data_path / "documentation"
        if pdf_path.exists():
            for pdf_file in pdf_path.glob("*.pdf"):
                all_documents.extend(self.process_pdf(str(pdf_file)))
        
        # Traiter les Markdown
        if pdf_path.exists():
            for md_file in pdf_path.glob("*.md"):
                all_documents.extend(self.process_markdown(str(md_file)))
        
        return all_documents
3.5 Fichier apps/ai-engine/models/response_generator.py
python
from typing import Dict, Any, List, Optional
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch


from ..config.settings import ai_settings
from ..rag.vector_store import VectorStore
from ..utils.intent_detector import IntentDetector


class ResponseGenerator:
    def __init__(self):
        self.vector_store = VectorStore()
        self.intent_detector = IntentDetector()
        
        # Charger le modèle LLM
        self.tokenizer = AutoTokenizer.from_pretrained(ai_settings.LLM_MODEL_NAME)
        
        device = "cuda" if ai_settings.LLM_DEVICE == "cuda" and torch.cuda.is_available() else "cpu"
        
        self.model = AutoModelForCausalLM.from_pretrained(
            ai_settings.LLM_MODEL_NAME,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            device_map=device
        )
        
        # Pipeline de génération
        self.generator = pipeline(
            "text-generation",
            model=self.model,
            tokenizer=self.tokenizer,
            device=0 if device == "cuda" else -1
        )
    
    def generate_response(
        self,
        message: str,
        conversation_history: List[Dict[str, str]] = None,
        conversation_id: str = None
    ) -> Dict[str, Any]:
        """
        Génère une réponse intelligente basée sur RAG et LLM
        """
        # Détecter l'intention
        intent = self.intent_detector.detect(message)
        
        # Récupérer le contexte pertinent depuis la base vectorielle
        relevant_contexts = self.vector_store.get_relevant_context(message)
        
        # Vérifier si escalade nécessaire
        needs_escalation = self._check_escalation_needed(message, intent)
        
        if needs_escalation:
            return {
                "response": self._generate_escalation_message(intent),
                "needs_escalation": True,
                "category": intent,
                "confidence": 0.5
            }
        
        # Construire le prompt avec contexte RAG
        prompt = self._build_prompt(message, relevant_contexts, conversation_history, intent)
        
        # Générer la réponse
        generated_text = self.generator(
            prompt,
            max_new_tokens=ai_settings.LLM_MAX_TOKENS,
            temperature=ai_settings.LLM_TEMPERATURE,
            do_sample=True,
            top_p=0.95,
            num_return_sequences=1
        )[0]['generated_text']
        
        # Extraire uniquement la réponse (après le prompt)
        response = self._extract_response(generated_text, prompt)
        
        # Ajouter les liens pertinents
        response_with_links = self._add_relevant_links(response, intent)
        
        return {
            "response": response_with_links,
            "needs_escalation": False,
            "category": intent,
            "confidence": 0.85,
            "sources": [ctx['metadata'] for ctx in relevant_contexts[:3]]
        }
    
    def _build_prompt(
        self,
        message: str,
        contexts: List[Dict[str, Any]],
        conversation_history: List[Dict[str, str]],
        intent: str
    ) -> str:
        """
        Construit le prompt pour le LLM avec RAG
        """
        system_prompt = """Tu es un assistant virtuel du service client Free Mobile. 
Tu dois répondre de manière professionnelle, claire et concise aux questions des clients.
Utilise les informations fournies dans le contexte pour répondre avec précision.
Si tu n'es pas sûr de la réponse, dis-le honnêtement et propose de transférer vers un conseiller.
Reste toujours courtois et empathique."""


        # Ajouter le contexte RAG
        context_str = "\n\n".join([
            f"[Source {i+1}] {ctx['content']}"
            for i, ctx in enumerate(contexts[:3])
        ])
        
        # Ajouter l'historique de conversation
        history_str = ""
        if conversation_history:
            history_str = "\n".join([
                f"{msg['role'].capitalize()}: {msg['content']}"
                for msg in conversation_history[-5:]  # 5 derniers messages
            ])
        
        prompt = f"""{system_prompt}


Contexte de la base de connaissances:
{context_str if context_str else "Aucun contexte spécifique trouvé."}


Historique de la conversation:
{history_str if history_str else "Nouvelle conversation"}


Client: {message}
il faut continuer
python
Assistant:"""
        
        return prompt
    
    def _extract_response(self, generated_text: str, prompt: str) -> str:
        """
        Extrait la réponse du texte généré
        """
        # Retirer le prompt du texte généré
        response = generated_text[len(prompt):].strip()
        
        # Nettoyer la réponse
        response = response.split("\n\n")[0]  # Prendre seulement le premier paragraphe
        response = response.replace("Assistant:", "").strip()
        
        return response
    
    def _check_escalation_needed(self, message: str, intent: str) -> bool:
        """
        Détermine si une escalade vers un humain est nécessaire
        """
        escalation_keywords = [
            "parler à un conseiller",
            "agent humain",
            "personne réelle",
            "très urgent",
            "problème grave",
            "remboursement",
            "résilier",
            "résiliation",
            "plainte",
            "réclamation officielle"
        ]
        
        message_lower = message.lower()
        
        # Vérifier les mots-clés d'escalade
        if any(keyword in message_lower for keyword in escalation_keywords):
            return True
        
        # Escalade automatique pour certaines intentions
        if intent in ["resiliation", "reclamation", "litige"]:
            return True
        
        return False
    
    def _generate_escalation_message(self, intent: str) -> str:
        """
        Génère un message d'escalade approprié
        """
        messages = {
            "resiliation": "Je comprends que vous souhaitez résilier votre abonnement. Cette demande nécessite l'intervention d'un conseiller. Un membre de notre équipe va prendre en charge votre demande dans les plus brefs délais.",
            "reclamation": "Je prends note de votre réclamation. Pour traiter votre demande de manière appropriée, je vais la transférer à un conseiller qui pourra vous aider efficacement.",
            "litige": "Votre situation nécessite une attention particulière. Un conseiller spécialisé va examiner votre cas et vous contacter rapidement.",
            "default": "Votre demande nécessite l'intervention d'un conseiller. Un membre de notre équipe va prendre en charge votre conversation dans quelques instants."
        }
        
        return messages.get(intent, messages["default"])
    
    def _add_relevant_links(self, response: str, intent: str) -> str:
        """
        Ajoute des liens pertinents à la réponse
        """
        links_by_intent = {
            "facturation": f"\n\n📄 Pour plus d'informations sur la facturation: {ai_settings.FREE_MOBILE_FAQ_URL}facturation/",
            "technique": f"\n\n🔧 Consultez notre guide technique: {ai_settings.FREE_MOBILE_FAQ_URL}parametrage/",
            "forfait": f"\n\n📱 Gérez votre forfait: {ai_settings.FREE_MOBILE_ESPACE_CLIENT_URL}",
            "general": f"\n\n💡 FAQ complète: {ai_settings.FREE_MOBILE_FAQ_URL}"
        }
        
        additional_link = links_by_intent.get(intent, links_by_intent["general"])
        
        return response + additional_link
3.6 Fichier apps/ai-engine/utils/intent_detector.py
python
from typing import Dict, List
import re


class IntentDetector:
    def __init__(self):
        self.intent_patterns = {
            "facturation": [
                r"\bfacture\b", r"\bpaiement\b", r"\bprélèvement\b",
                r"\bmontant\b", r"\bpayer\b", r"\btarif\b", r"\bcoût\b",
                r"\bfacturé\b", r"\bfacturation\b", r"\bprix\b"
            ],
            "technique": [
                r"\bpanne\b", r"\bréseau\b", r"\bconnexion\b", r"\bdébit\b",
                r"\b4g\b", r"\b5g\b", r"\binternet\b", r"\bne fonctionne pas\b",
                r"\bproblème technique\b", r"\bcoupure\b", r"\bsignal\b"
            ],
            "forfait": [
                r"\bforfait\b", r"\boption\b", r"\bchangement\b", r"\bmigration\b",
                r"\bmodifier\b", r"\baugmenter\b", r"\bréduire\b", r"\bdata\b",
                r"\bgiga\b", r"\bgo\b"
            ],
            "resiliation": [
                r"\brésilier\b", r"\brésiliation\b", r"\barrêter\b",
                r"\bannuler\b", r"\bquitter\b", r"\bpartir\b"
            ],
            "reclamation": [
                r"\bréclamation\b", r"\bplainte\b", r"\binsatisfait\b",
                r"\bmécontent\b", r"\bproblème grave\b", r"\binacceptable\b"
            ],
            "activation": [
                r"\bactiver\b", r"\bactivation\b", r"\bnouveau\b",
                r"\bnouvelle ligne\b", r"\bcommande\b", r"\bsim\b"
            ],
            "assistance": [
                r"\baide\b", r"\baider\b", r"\bcomment\b", r"\bexpliquer\b",
                r"\bguide\b", r"\btutoriel\b"
            ]
        }
    
    def detect(self, message: str) -> str:
        """
        Détecte l'intention du message
        """
        message_lower = message.lower()
        scores = {}
        
        for intent, patterns in self.intent_patterns.items():
            score = 0
            for pattern in patterns:
                if re.search(pattern, message_lower):
                    score += 1
            scores[intent] = score
        
        # Retourner l'intention avec le score le plus élevé
        if max(scores.values()) > 0:
            return max(scores, key=scores.get)
        
        return "general"
    
    def get_category(self, intent: str) -> str:
        """
        Retourne la catégorie pour le ticketing
        """
        category_mapping = {
            "facturation": "Facturation",
            "technique": "Technique",
            "forfait": "Forfait",
            "resiliation": "Résiliation",
            "reclamation": "Réclamation",
            "activation": "Activation",
            "assistance": "Assistance",
            "general": "Général"
        }
        
        return category_mapping.get(intent, "Général")
3.7 Fichier apps/ai-engine/api.py
python
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import uvicorn


from .models.response_generator import ResponseGenerator
from .rag.vector_store import VectorStore
from .rag.document_processor import DocumentProcessor
from .config.settings import ai_settings


app = FastAPI(
    title="Free Mobile AI Engine",
    description="Moteur IA avec RAG pour le chatbot Free Mobile",
    version="1.0.0"
)


# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Instances globales
response_generator = None
vector_store = None


class GenerateRequest(BaseModel):
    message: str
    conversation_history: Optional[List[Dict[str, str]]] = None
    conversation_id: Optional[str] = None


class GenerateResponse(BaseModel):
    response: str
    needs_escalation: bool
    category: str
    confidence: float
    sources: Optional[List[Dict[str, Any]]] = None


@app.on_event("startup")
async def startup_event():
    """Initialisation au démarrage"""
    global response_generator, vector_store
    
    print("🚀 Initialisation du moteur IA...")
    
    # Initialiser le vector store
    vector_store = VectorStore()
    
    # Initialiser le générateur de réponses
    response_generator = ResponseGenerator()
    
    print("✅ Moteur IA initialisé")


@app.get("/")
async def root():
    return {
        "status": "online",
        "service": "Free Mobile AI Engine",
        "version": "1.0.0"
    }


@app.post("/api/generate", response_model=GenerateResponse)
async def generate_response(request: GenerateRequest):
    """
    Génère une réponse intelligente
    """
    try:
        result = response_generator.generate_response(
            message=request.message,
            conversation_history=request.conversation_history,
            conversation_id=request.conversation_id
        )
        
        return GenerateResponse(**result)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur de génération: {str(e)}")


@app.post("/api/ingest-documents")
async def ingest_documents():
    """
    Ingère tous les documents dans la base vectorielle
    """
    try:
        processor = DocumentProcessor()
        documents = processor.process_all_documents()
        
        if not documents:
            return {
                "status": "warning",
                "message": "Aucun document trouvé à ingérer",
                "count": 0
            }
        
        # Préparer les données pour ChromaDB
        doc_contents = [doc['content'] for doc in documents]
        metadatas = [doc['metadata'] for doc in documents]
        
        # Ajouter à la base vectorielle
        vector_store.add_documents(doc_contents, metadatas)
        
        return {
            "status": "success",
            "message": f"{len(documents)} documents ingérés avec succès",
            "count": len(documents)
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur d'ingestion: {str(e)}")


@app.get("/api/stats")
async def get_stats():
    """
    Retourne les statistiques du moteur IA
    """
    return {
        "vector_store_count": vector_store.get_collection_count(),
        "model_name": ai_settings.LLM_MODEL_NAME,
        "embedding_model": ai_settings.EMBEDDING_MODEL,
        "rag_top_k": ai_settings.RAG_TOP_K
    }


@app.delete("/api/reset-vector-store")
async def reset_vector_store():
    """
    Réinitialise la base vectorielle
    """
    try:
        vector_store.delete_collection()
        
        # Recréer la collection
        global vector_store
        vector_store = VectorStore()
        
        return {
            "status": "success",
            "message": "Base vectorielle réinitialisée"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erreur de réinitialisation: {str(e)}")


if __name__ == "__main__":
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8001,
        reload=True
    )
PARTIE 4 : SURVEILLANCE MASTODON
4.1 Structure apps/social-monitor/
apps/social-monitor/
├── collectors/
│   ├── __init__.py
│   ├── mastodon_collector.py
│   └── stream_listener.py
├── processors/
│   ├── __init__.py
│   ├── post_analyzer.py
│   ├── complaint_detector.py
│   └── link_generator.py
├── responders/
│   ├── __init__.py
│   └── auto_responder.py
├── config/
│   ├── __init__.py
│   └── mastodon_config.py
├── main.py
├── requirements.txt
└── Dockerfile
4.2 Fichier apps/social-monitor/config/mastodon_config.py
python
from pydantic_settings import BaseSettings
import os
from dotenv import load_dotenv


load_dotenv()


class MastodonSettings(BaseSettings):
    # Mastodon API
    INSTANCE_URL: str = os.getenv("MASTODON_INSTANCE_URL", "https://mastodon.social")
    CLIENT_ID: str = os.getenv("MASTODON_CLIENT_ID", "")
    CLIENT_SECRET: str = os.getenv("MASTODON_CLIENT_SECRET", "")
    ACCESS_TOKEN: str = os.getenv("MASTODON_ACCESS_TOKEN", "")
    
    # Monitoring
    MONITOR_HASHTAGS: list = os.getenv("MASTODON_MONITOR_HASHTAGS", "Free,FreeMobile,SAVFree").split(",")
    
    # Backend
    BACKEND_API_URL: str = os.getenv("BACKEND_API_URL", "http://localhost:8000")
    CHATBOT_BASE_URL: str = os.getenv("FRONTEND_URL", "http://localhost:8501")
    
    class Config:
        env_file = ".env"


mastodon_settings = MastodonSettings()
4.3 Fichier apps/social-monitor/collectors/stream_listener.py
python
from mastodon import StreamListener
import asyncio
from typing import Callable
import logging


logger = logging.getLogger(__name__)


class FreeStreamListener(StreamListener):
    def __init__(
        self,
        on_update_callback: Callable,
        on_notification_callback: Callable = None
    ):
        self.on_update_callback = on_update_callback
        self.on_notification_callback = on_notification_callback
    
    def on_update(self, status):
        """
        Appelé lors d'un nouveau post
        """
        try:
            logger.info(f"Nouveau post détecté de @{status.account.username}")
            
            # Appeler le callback de manière asynchrone
            asyncio.create_task(self.on_update_callback(status))
            
        except Exception as e:
            logger.error(f"Erreur lors du traitement du post: {e}")
    
    def on_notification(self, notification):
        """
        Appelé lors d'une notification
        """
        try:
            if notification.type == "mention":
                logger.info(f"Mention détectée de @{notification.account.username}")
                
                if self.on_notification_callback:
                    asyncio.create_task(self.on_notification_callback(notification))
        
        except Exception as e:
            logger.error(f"Erreur lors du traitement de la notification: {e}")
    
    def on_delete(self, status_id):
        """Appelé lors de la suppression d'un post"""
        logger.info(f"Post {status_id} supprimé")
    
    def handle_heartbeat(self):
        """Appelé périodiquement pour maintenir la connexion"""
        logger.debug("Heartbeat reçu")
4.4 Fichier apps/social-monitor/processors/complaint_detector.py
python
import re
from typing import Dict, Any


class ComplaintDetector:
    def __init__(self):
        self.complaint_keywords = [
            # Français
            "problème", "bug", "panne", "ne fonctionne pas",
            "dysfonctionnement", "erreur", "impossible",
            "réclamation", "plainte", "insatisfait", "mécontent",
            "arnaque", "scandale", "honte", "inadmissible",
            "catastrophe", "nul", "pourri", "incompétent",
            
            # Expressions
            "ça ne marche pas", "j'en ai marre", "c'est inadmissible",
            "toujours le même problème", "aucune aide"
        ]
        
        self.urgency_keywords = [
            "urgent", "très urgent", "critique", "grave",
            "immédiatement", "tout de suite", "rapidement"
        ]
        
        self.negative_emojis = ["😠", "😡", "🤬", "😤", "💢", "😾", "😖", "😫", "😩"]
    
    def is_complaint(self, content: str) -> bool:
        """
        Détermine si le contenu est une réclamation
        """
        content_lower = content.lower()
        
        # Vérifier les mots-clés de réclamation
        complaint_score = sum(
            1 for keyword in self.complaint_keywords
            if keyword in content_lower
        )
        
        # Vérifier les emojis négatifs
        emoji_score = sum(
            1 for emoji in self.negative_emojis
            if emoji in content
        )
        
        # Points d'exclamation multiples (!!!)
        exclamation_score = len(re.findall(r'!{2,}', content))
        
        # Mots en majuscules
        caps_words = len(re.findall(r'\b[A-Z]{3,}\b', content))
        
        total_score = complaint_score + emoji_score + exclamation_score + (caps_words * 0.5)
        
        return total_score >= 2
    
    def get_urgency_level(self, content: str) -> str:
        """
        Détermine le niveau d'urgence
        """
        content_lower = content.lower()
        
        urgency_count = sum(
            1 for keyword in self.urgency_keywords
            if keyword in content_lower
        )
        
        if urgency_count >= 2:
            return "HIGH"
        elif urgency_count == 1:
            return "MEDIUM"
        else:
            return "LOW"
    
    def analyze_post(self, status) -> Dict[str, Any]:
        """
        Analyse complète d'un post
        """
        content = status.content
        
        # Retirer les balises HTML
        import html
        content_clean = html.unescape(re.sub('<[^<]+?>', '', content))
        
        is_complaint = self.is_complaint(content_clean)
        urgency = self.get_urgency_level(content_clean)
        
        return {
            "is_complaint": is_complaint,
            "urgency": urgency,
            "content": content_clean,
            "author": status.account.username,
            "post_id": status.id,
            "url": status.url
        }
4.5 Fichier apps/social-monitor/processors/link_generator.py
python
import hashlib
from datetime import datetime
from typing import Dict, Any
import httpx


class LinkGenerator:
    def __init__(self, backend_url: str, chatbot_url: str):
        self.backend_url = backend_url
        self.chatbot_url = chatbot_url
    
    async def generate_contact_link(self, status) -> Dict[str, Any]:
        """
        Génère un lien de contact unique
        """
        # Créer un identifiant unique
        user_id = status.account.id
        timestamp = datetime.now().isoformat()
        
        # Créer un token unique
        token_data = f"{user_id}_{status.id}_{timestamp}"
        token = hashlib.md5(token_data.encode()).hexdigest()[:12]
        
        # Préparer le contexte
        context = {
            "mastodon_user": status.account.username,
            "mastodon_id": str(status.id),
            "initial_message": status.content[:500],
            "timestamp": timestamp,
            "source": "mastodon",
            "url": status.url
        }
        
        # Sauvegarder le contexte dans le backend
        await self._save_context(token, context)
        
        # Générer le lien
        contact_link = f"{self.chatbot_url}?token={token}&source=mastodon"
        
        return {
            "token": token,
            "link": contact_link,
            "context": context
        }
    
    async def _save_context(self, token: str, context: Dict[str, Any]):
        """
        Sauvegarde le contexte via l'API backend
        """
        async with httpx.AsyncClient() as client:
            try:
                await client.post(
                    f"{self.backend_url}/api/v1/mastodon/save-context",
                    json={"token": token, "context": context}
                )
            except Exception as e:
                print(f"Erreur lors de la sauvegarde du contexte: {e}")
4.6 Fichier apps/social-monitor/responders/auto_responder.py
python
from mastodon import Mastodon
import logging


logger = logging.getLogger(__name__)


class AutoResponder:
    def __init__(self, mastodon_client: Mastodon):
        self.mastodon = mastodon_client
        
        self.response_templates = {
            "HIGH": """Bonjour @{username} ! 👋


Je comprends votre situation urgente concernant Free Mobile.
Pour un traitement prioritaire, je vous invite à continuer votre conversation avec notre assistant virtuel :


🔗 {contact_link}


Notre équipe va traiter votre demande dans les plus brefs délais.


#SAVFree #Support""",
            
            "MEDIUM": """Bonjour @{username} ! 👋


J'ai bien noté votre message concernant Free Mobile.
Pour un support personnalisé et rapide, je vous invite à poursuivre avec notre assistant :


🔗 {contact_link}


Nous sommes là pour vous aider !


#SAVFree #Support""",
            
            "LOW": """Bonjour @{username} ! 👋


Merci pour votre message. Notre assistant virtuel est disponible pour vous aider :


🔗 {contact_link}


#SAVFree"""
        }
    
    async def send_reply(
        self,
        status,
        contact_link: str,
        urgency: str = "MEDIUM"
    ) -> bool:
        """
        Envoie une réponse automatique
        """
        try:
            username = status.account.username
            
            # Sélectionner le template approprié
            template = self.response_templates.get(urgency, self.response_templates["MEDIUM"])
            
            # Formater le message
            reply_text = template.format(
                username=username,
                contact_link=contact_link
            )
            
            # Envoyer la réponse
            self.mastodon.status_reply(
                to_status=status,
                status=reply_text,
                visibility="public"
            )
            
            logger.info(f"Réponse envoyée à @{username}")
            return True
            
        except Exception as e:
            logger.error(f"Erreur lors de l'envoi de la réponse: {e}")
            return False
4.7 Fichier apps/social-monitor/collectors/mastodon_collector.py
python
from mastodon import Mastodon
import asyncio
import logging
from typing import Optional


from ..config.mastodon_config import mastodon_settings
from ..processors.complaint_detector import ComplaintDetector
from ..processors.link_generator import LinkGenerator
from ..responders.auto_responder import AutoResponder
from .stream_listener import FreeStreamListener
import httpx


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MastodonCollector:
    def __init__(self):
        # Initialiser le client Mastodon
        self.mastodon = Mastodon(
            access_token=mastodon_settings.ACCESS_TOKEN,
            api_base_url=mastodon_settings.INSTANCE_URL
        )
        
        # Initialiser les composants
        self.complaint_detector = ComplaintDetector()
        self.link_generator = LinkGenerator(
            backend_url=mastodon_settings.BACKEND_API_URL,
            chatbot_url=mastodon_settings.CHATBOT_BASE_URL
        )
        self.auto_responder = AutoResponder(self.mastodon)
    
    def is_free_related(self, status) -> bool:
        """
        Vérifie si le post est lié à Free Mobile
        """
        content = status.content.lower()
        hashtags = [tag.name.lower() for tag in status.tags]
        
        free_keywords = ['free', 'freemobile', 'free mobile', 'sav free']
        monitored_hashtags = [tag.lower() for tag in mastodon_settings.MONITOR_HASHTAGS]
        
        # Vérifier les hashtags
        if any(tag in hashtags for tag in monitored_hashtags):
            return True
        
        # Vérifier le contenu
        if any(keyword in content for keyword in free_keywords):
            return True
        
        return False
    
    async def process_post(self, status):
        """
        Traite un post lié à Free Mobile
        """
        try:
            # Vérifier si c'est lié à Free
            if not self.is_free_related(status):
                return
            
            logger.info(f"Post Free Mobile détecté de @{status.account.username}")
            
            # Analyser le post
            analysis = self.complaint_detector.analyze_post(status)
            
            # Si c'est une réclamation
            if analysis["is_complaint"]:
                logger.info(f"Réclamation détectée (urgence: {analysis['urgency']})")
                
                # Générer un lien de contact
                link_data = await self.link_generator.generate_contact_link(status)
                
                # Envoyer une réponse automatique
                await self.auto_responder.send_reply(
                    status=status,
                    contact_link=link_data["link"],
                    urgency=analysis["urgency"]
                )
                
                # Sauvegarder dans la base de données
                await self.save_to_database(status, analysis, link_data)
        
        except Exception as e:
            logger.error(f"Erreur lors du traitement du post: {e}")
    
    async def process_mention(self, notification):
        """
        Traite une mention
        """
        try:
            status = notification.status
            logger.info(f"Mention traitée de @{status.account.username}")
            
            # Traiter comme un post normal
            await self.process_post(status)
        
        except Exception as e:
            logger.error(f"Erreur lors du traitement de la mention: {e}")
    
    async def save_to_database(self, status, analysis, link_data):
        """
        Sauvegarde les données dans la base via l'API
        """
        async with httpx.AsyncClient() as client:
            try:
                await client.post(
                    f"{mastodon_settings.BACKEND_API_URL}/api/v1/mastodon/posts",
                    json={
                        "mastodon_id": str(status.id),
                        "author_username": status.account.username,
                        "content": analysis["content"],
                        "is_complaint": analysis["is_complaint"],
                        "urgency": analysis["urgency"],
                        "contact_link": link_data["link"],
                        "context_token": link_data["token"]
                    }
                )
                logger.info("Données sauvegardées dans la base")
            
            except Exception as e:
                logger.error(f"Erreur lors de la sauvegarde: {e}")
    
    def start_streaming(self):
        """
        Démarre l'écoute des streams Mastodon
        """
        logger.info("Démarrage de la surveillance Mastodon...")
        
        # Créer le listener
        listener = FreeStreamListener(
            on_update_callback=self.process_post,
            on_notification_callback=self.process_mention
        )
        
        # Démarrer les streams
        try:
            # Stream des hashtags
            for hashtag in mastodon_settings.MONITOR_HASHTAGS:
                logger.info(f"Surveillance du hashtag: #{hashtag}")
                self.mastodon.stream_hashtag(
                    tag=hashtag,
                    listener=listener,
                    run_async=True,
                    reconnect_async=True
                )
            
            # Stream des notifications (mentions)
            logger.info("Surveillance des mentions activée")
            self.mastodon.stream_user(
                listener=listener,
                run_async=True,
                reconnect_async=True
            )
            
            logger.info("✅ Surveillance Mastodon active")
            
            # Garder le programme actif
            while True:
                asyncio.sleep(60)
        
        except KeyboardInterrupt:
            logger.info("Arrêt de la surveillance")
        except Exception as e:
            logger.error(f"Erreur fatale: {e}")
4.8 Fichier apps/social-monitor/main.py
python
import asyncio
import logging
from collectors.mastodon_collector import MastodonCollector


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


logger = logging.getLogger(__name__)


async def main():
    """
    Point d'entrée principal
    """
    logger.info("🚀 Démarrage du Social Monitor")
    
    try:
        collector = MastodonCollector()
        collector.start_streaming()
    
    except Exception as e:
        logger.error(f"Erreur fatale: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main())
Voulez-vous que je continue avec la Partie 5 : Frontend Streamlit et le reste (Docker Compose, scripts de déploiement, données d'entraînement) ? 🚀
oui continue
PARTIE 5 : FRONTEND STREAMLIT
5.1 Structure apps/frontend/
apps/frontend/
├── pages/
│   ├── 01_🏠_Dashboard.py
│   ├── 02_💬_Chat_Support.py
│   ├── 03_📊_Analytics.py
│   ├── 04_👥_Conversations.py
│   ├── 05_⚙️_Configuration.py
│   └── 06_🎫_Tickets.py
├── components/
│   ├── __init__.py
│   ├── chat_widget.py
│   ├── analytics_charts.py
│   ├── ticket_manager.py
│   └── contact_form.py
├── utils/
│   ├── __init__.py
│   ├── api_client.py
│   ├── auth.py
│   ├── session_manager.py
│   └── validators.py
├── static/
│   ├── css/
│   │   └── custom.css
│   └── images/
│       └── logo.png
├── config/
│   ├── __init__.py
│   └── settings.py
├── app.py
├── requirements.txt
└── Dockerfile
5.2 Fichier apps/frontend/config/settings.py
python
from pydantic_settings import BaseSettings
import os
from dotenv import load_dotenv


load_dotenv()


class FrontendSettings(BaseSettings):
    # Application
    APP_NAME: str = "Free Mobile - Chatbot SAV"
    APP_VERSION: str = "1.0.0"
    
    # Backend API
    BACKEND_API_URL: str = os.getenv("BACKEND_API_URL", "http://localhost:8000")
    
    # Streamlit
    PAGE_TITLE: str = "SAV Free Mobile"
    PAGE_ICON: str = "📱"
    LAYOUT: str = "wide"
    
    # Session
    SESSION_TIMEOUT: int = 3600  # 1 heure
    
    class Config:
        env_file = ".env"


frontend_settings = FrontendSettings()
5.3 Fichier apps/frontend/utils/session_manager.py
python
import streamlit as st
from datetime import datetime, timedelta
from typing import Any, Optional


def init_session_state():
    """
    Initialise les variables de session
    """
    # Authentification
    if 'authenticated' not in st.session_state:
        st.session_state.authenticated = False
    
    if 'user' not in st.session_state:
        st.session_state.user = None
    
    # Conversation
    if 'conversation_id' not in st.session_state:
        st.session_state.conversation_id = None
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    # Context token (pour Mastodon)
    if 'context_token' not in st.session_state:
        st.session_state.context_token = None
    
    # User info pour le formulaire
    if 'user_info' not in st.session_state:
        st.session_state.user_info = {}
    
    # Dernière activité
    if 'last_activity' not in st.session_state:
        st.session_state.last_activity = datetime.now()


def update_activity():
    """
    Met à jour le timestamp de dernière activité
    """
    st.session_state.last_activity = datetime.now()


def is_session_expired(timeout: int = 3600) -> bool:
    """
    Vérifie si la session a expiré
    """
    if 'last_activity' not in st.session_state:
        return True
    
    elapsed = datetime.now() - st.session_state.last_activity
    return elapsed.total_seconds() > timeout


def reset_conversation():
    """
    Réinitialise la conversation
    """
    st.session_state.conversation_id = None
    st.session_state.messages = []


def set_user_info(full_name: str, phone_number: str, email: Optional[str] = None):
    """
    Stocke les informations utilisateur
    """
    st.session_state.user_info = {
        "full_name": full_name,
        "phone_number": phone_number,
        "email": email
    }


def get_user_info() -> dict:
    """
    Récupère les informations utilisateur
    """
    return st.session_state.get('user_info', {})
5.4 Fichier apps/frontend/utils/api_client.py
python
import httpx
from typing import Dict, Any, List, Optional
import streamlit as st
from config.settings import frontend_settings


class APIClient:
    def __init__(self):
        self.base_url = frontend_settings.BACKEND_API_URL
        self.timeout = 30.0
    
    async def send_message(
        self,
        message: str,
        conversation_id: Optional[str] = None,
        context_token: Optional[str] = None,
        user_info: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        Envoie un message au chatbot
        """
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            try:
                response = await client.post(
                    f"{self.base_url}/api/v1/chat/message",
                    json={
                        "message": message,
                        "conversation_id": conversation_id,
                        "context_token": context_token,
                        "user_info": user_info
                    }
                )
                response.raise_for_status()
                return response.json()
            
            except httpx.HTTPError as e:
                st.error(f"Erreur de communication avec le serveur: {e}")
                return None
    
    async def get_conversation_messages(
        self,
        conversation_id: str
    ) -> List[Dict[str, Any]]:
        """
        Récupère l'historique d'une conversation
        """
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            try:
                response = await client.get(
                    f"{self.base_url}/api/v1/chat/conversation/{conversation_id}/messages"
                )
                response.raise_for_status()
                return response.json()
            
            except httpx.HTTPError as e:
                st.error(f"Erreur lors de la récupération des messages: {e}")
                return []
    
    async def get_tickets(
        self,
        status: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Récupère les tickets
        """
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            try:
                params = {"status": status} if status else {}
                response = await client.get(
                    f"{self.base_url}/api/v1/tickets",
                    params=params
                )
                response.raise_for_status()
                return response.json()
            
            except httpx.HTTPError as e:
                st.error(f"Erreur lors de la récupération des tickets: {e}")
                return []
    
    async def get_analytics(
        self,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Récupère les analytics
        """
        async with httpx.AsyncClient(timeout=self.timeout) as client:
            try:
                params = {}
                if start_date:
                    params['start_date'] = start_date
                if end_date:
                    params['end_date'] = end_date
                
                response = await client.get(
                    f"{self.base_url}/api/v1/analytics",
                    params=params
                )
                response.raise_for_status()
                return response.json()
            
            except httpx.HTTPError as e:
                st.error(f"Erreur lors de la récupération des analytics: {e}")
                return {}
5.5 Fichier apps/frontend/components/contact_form.py
python
import streamlit as st
import re
from utils.session_manager import set_user_info


class ContactForm:
    @staticmethod
    def validate_phone(phone: str) -> bool:
        """
        Valide un numéro de téléphone français
        """
        # Format: 06/07 XX XX XX XX ou +33 6/7 XX XX XX XX
        pattern = r'^(?:(?:\+|00)33|0)[67](?:[\s.-]?\d{2}){4}$'
        return bool(re.match(pattern, phone.replace(' ', '')))
    
    @staticmethod
    def validate_email(email: str) -> bool:
        """
        Valide une adresse email
        """
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return bool(re.match(pattern, email))
    
    @staticmethod
    def render():
        """
        Affiche le formulaire de contact
        """
        st.markdown("### 📝 Informations de contact")
        st.markdown("Pour mieux vous aider, merci de renseigner vos informations :")
        
        with st.form("contact_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                full_name = st.text_input(
                    "Nom et Prénom *",
                    placeholder="Ex: Jean Dupont"
                )
            
            with col2:
                phone_number = st.text_input(
                    "Numéro de téléphone *",
                    placeholder="Ex: 06 12 34 56 78"
                )
            
            email = st.text_input(
                "Email (optionnel)",
                placeholder="Ex: jean.dupont@email.com"
            )
            
            submitted = st.form_submit_button("Continuer vers le chat 💬")
            
            if submitted:
                # Validation
                errors = []
                
                if not full_name or len(full_name) < 3:
                    errors.append("Veuillez entrer votre nom complet")
                
                if not phone_number:
                    errors.append("Le numéro de téléphone est obligatoire")
                elif not ContactForm.validate_phone(phone_number):
                    errors.append("Format de téléphone invalide (Ex: 06 12 34 56 78)")
                
                if email and not ContactForm.validate_email(email):
                    errors.append("Format d'email invalide")
                
                if errors:
                    for error in errors:
                        st.error(error)
                    return False
                
                # Sauvegarder les informations
                set_user_info(
                    full_name=full_name,
                    phone_number=phone_number,
                    email=email if email else None
                )
                
                st.success("✅ Informations enregistrées !")
                return True
        
        return False
5.6 Fichier apps/frontend/components/chat_widget.py
python
import streamlit as st
from datetime import datetime
from typing import Dict, List, Any


class ChatWidget:
    def __init__(self):
        self.bot_avatar = "🤖"
        self.user_avatar = "👤"
    
    def display_message(self, message: Dict[str, Any]):
        """
        Affiche un message dans le chat
        """
        role = message.get("role", "user")
        content = message.get("content", "")
        timestamp = message.get("created_at", datetime.now().isoformat())
        
        # Formater le timestamp
        try:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            time_str = dt.strftime("%H:%M")
        except:
            time_str = datetime.now().strftime("%H:%M")
        
        if role == "user":
            with st.chat_message("user", avatar=self.user_avatar):
                st.markdown(content)
                st.caption(f"🕐 {time_str}")
        
        elif role == "assistant":
            with st.chat_message("assistant", avatar=self.bot_avatar):
                st.markdown(content)
                st.caption(f"🕐 {time_str}")
        
        elif role == "system":
            st.info(content)
    
    def display_suggested_links(self, links: List[Dict[str, str]]):
        """
        Affiche les liens suggérés
        """
        if not links:
            return
        
        st.markdown("---")
        st.markdown("### 🔗 Liens utiles")
        
        cols = st.columns(len(links))
        
        for i, link in enumerate(links):
            with cols[i]:
                st.markdown(
                    f"""
                    <a href="{link['url']}" target="_blank" style="text-decoration: none;">
                        <div style="
                            padding: 15px;
                            border-radius: 10px;
                            background-color: #f0f2f6;
                            text-align: center;
                            border: 1px solid #e0e0e0;
                        ">
                            <h4 style="margin: 0; color: #1f77b4;">{link['title']}</h4>
                            <p style="margin: 5px 0 0 0; font-size: 0.9em; color: #666;">
                                {link.get('description', '')}
                            </p>
                        </div>
                    </a>
                    """,
                    unsafe_allow_html=True
                )
    
    def display_typing_indicator(self):
        """
        Affiche un indicateur de saisie
        """
        with st.chat_message("assistant", avatar=self.bot_avatar):
            st.markdown("💭 En train d'écrire...")
    
    def display_welcome_message(self):
        """
        Affiche le message de bienvenue
        """
        welcome_msg = """
        👋 **Bonjour ! Je suis l'assistant virtuel Free Mobile.**
        
        Je suis là pour vous aider avec :
        - 📱 Questions sur votre forfait
        - 💰 Facturation et paiements
        - 🔧 Problèmes techniques
        - ⚙️ Paramétrage et activation
        - 📞 Et bien plus encore !
        
        Comment puis-je vous aider aujourd'hui ?
        """
        
        with st.chat_message("assistant", avatar=self.bot_avatar):
            st.markdown(welcome_msg)
5.7 Fichier apps/frontend/components/analytics_charts.py
python
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import pandas as pd
from typing import Dict, Any, List


class AnalyticsCharts:
    @staticmethod
    def render_kpi_cards(data: Dict[str, Any]):
        """
        Affiche les cartes KPI
        """
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric(
                label="Total Conversations",
                value=data.get("total_conversations", 0),
                delta=data.get("conversations_delta", 0)
            )
        
        with col2:
            st.metric(
                label="Tickets Ouverts",
                value=data.get("open_tickets", 0),
                delta=data.get("tickets_delta", 0),
                delta_color="inverse"
            )
        
        with col3:
            st.metric(
                label="Taux de Résolution",
                value=f"{data.get('resolution_rate', 0):.1f}%",
                delta=f"{data.get('resolution_delta', 0):.1f}%"
            )
        
        with col4:
            st.metric(
                label="Temps Moyen de Réponse",
                value=f"{data.get('avg_response_time', 0):.1f}s",
                delta=f"{data.get('response_time_delta', 0):.1f}s",
                delta_color="inverse"
            )
    
    @staticmethod
    def render_conversations_chart(data: List[Dict[str, Any]]):
        """
        Graphique des conversations par jour
        """
        if not data:
            st.info("Aucune donnée disponible")
            return
        
        df = pd.DataFrame(data)
        
        fig = px.line(
            df,
            x='date',
            y='count',
            title='Évolution des conversations',
            labels={'date': 'Date', 'count': 'Nombre de conversations'}
        )
        
        fig.update_layout(
            hovermode='x unified',
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    @staticmethod
    def render_intent_distribution(data: Dict[str, int]):
        """
        Graphique de distribution des intentions
        """
        if not data:
            st.info("Aucune donnée disponible")
            return
        
        fig = px.pie(
            values=list(data.values()),
            names=list(data.keys()),
            title='Distribution des types de demandes',
            hole=0.4
        )
        
        fig.update_traces(textposition='inside', textinfo='percent+label')
        
        st.plotly_chart(fig, use_container_width=True)
    
    @staticmethod
    def render_ticket_status_chart(data: Dict[str, int]):
        """
        Graphique du statut des tickets
        """
        if not data:
            st.info("Aucune donnée disponible")
            return
        
        colors = {
            'OPEN': '#ff6b6b',
            'IN_PROGRESS': '#ffd93d',
            'RESOLVED': '#6bcf7f',
            'CLOSED': '#95a5a6'
        }
        
        fig = go.Figure(data=[
            go.Bar(
                x=list(data.keys()),
                y=list(data.values()),
                marker_color=[colors.get(k, '#3498db') for k in data.keys()],
                text=list(data.values()),
                textposition='auto'
            )
        ])
        
        fig.update_layout(
            title='Statut des tickets',
            xaxis_title='Statut',
            yaxis_title='Nombre',
            showlegend=False
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    @staticmethod
    def render_hourly_activity(data: List[Dict[str, Any]]):
        """
        Graphique d'activité par heure
        """
        if not data:
            st.info("Aucune donnée disponible")
            return
        
        df = pd.DataFrame(data)
        
        fig = go.Figure()
        
        fig.add_trace(go.Scatter(
            x=df['hour'],
            y=df['count'],
            mode='lines+markers',
            fill='tozeroy',
            name='Conversations'
        ))
        
        fig.update_layout(
            title='Activité par heure de la journée',
            xaxis_title='Heure',
            yaxis_title='Nombre de conversations',
            xaxis=dict(
                tickmode='linear',
                tick0=0,
                dtick=2
            )
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    @staticmethod
    def render_satisfaction_gauge(score: float):
        """
        Jauge de satisfaction
        """
        fig = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=score,
            domain={'x': [0, 1], 'y': [0, 1]},
            title={'text': "Score de Satisfaction"},
            delta={'reference': 80},
            gauge={
                'axis': {'range': [None, 100]},
                'bar': {'color': "darkblue"},
                'steps': [
                    {'range': [0, 50], 'color': "#ff6b6b"},
                    {'range': [50, 75], 'color': "#ffd93d"},
                    {'range': [75, 100], 'color': "#6bcf7f"}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': 90
                }
            }
        ))
        
        fig.update_layout(height=300)
        
        st.plotly_chart(fig, use_container_width=True)
5.8 Fichier apps/frontend/app.py
python
import streamlit as st
from streamlit_option_menu import option_menu
from config.settings import frontend_settings
from utils.session_manager import init_session_state, update_activity
from components.contact_form import ContactForm
import sys


# Configuration de la page
st.set_page_config(
    page_title=frontend_settings.PAGE_TITLE,
    page_icon=frontend_settings.PAGE_ICON,
    layout=frontend_settings.LAYOUT,
    initial_sidebar_state="expanded"
)


# CSS personnalisé
with open('static/css/custom.css') as f:
    st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)


# Initialisation de la session
init_session_state()


# Vérifier si on arrive depuis Mastodon
query_params = st.query_params
if 'token' in query_params:
    st.session_state.context_token = query_params['token']
    st.session_state.source = query_params.get('source', 'web')


# Header
col1, col2 = st.columns([1, 4])
with col1:
    st.image("static/images/logo.png", width=100)
with col2:
    st.title("🆓 Free Mobile - Support Client")
    st.caption(f"Version {frontend_settings.APP_VERSION}")


# Si pas d'informations utilisateur, afficher le formulaire
if not st.session_state.user_info:
    ContactForm.render()
    st.stop()


# Menu principal
selected = option_menu(
    menu_title=None,
    options=["Chat Support", "Mes Tickets", "Analytics"],
    icons=["chat-dots", "ticket-perforated", "graph-up"],
    menu_icon="cast",
    default_index=0,
    orientation="horizontal",
    styles={
        "container": {"padding": "0!important", "background-color": "#fafafa"},
        "icon": {"color": "orange", "font-size": "18px"},
        "nav-link": {
            "font-size": "16px",
            "text-align": "center",
            "margin": "0px",
            "--hover-color": "#eee",
        },
        "nav-link-selected": {"background-color": "#02ab21"},
    }
)


# Mettre à jour l'activité
update_activity()


# Redirection vers les pages
if selected == "Chat Support":
    # Importer et exécuter la page chat
    exec(open('pages/02_💬_Chat_Support.py').read())


elif selected == "Mes Tickets":
    exec(open('pages/06_🎫_Tickets.py').read())


elif selected == "Analytics":
    exec(open('pages/03_📊_Analytics.py').read())
5.9 Fichier apps/frontend/pages/02_💬_Chat_Support.py
python
import streamlit as st
import asyncio
from components.chat_widget import ChatWidget
from utils.api_client import APIClient
from utils.session_manager import get_user_info


# Initialiser les composants
chat_widget = ChatWidget()
api_client = APIClient()


st.title("💬 Support Client")


# Afficher les informations utilisateur
user_info = get_user_info()
with st.expander("ℹ️ Vos informations", expanded=False):
    st.write(f"**Nom:** {user_info.get('full_name', 'N/A')}")
    st.write(f"**Téléphone:** {user_info.get('phone_number', 'N/A')}")
    if user_info.get('email'):
        st.write(f"**Email:** {user_info['email']}")


# Container pour les messages
chat_container = st.container()


# Afficher le message de bienvenue si nouveau
if not st.session_state.messages:
    chat_widget.display_welcome_message()


# Afficher l'historique des messages
with chat_container:
    for message in st.session_state.messages:
        chat_widget.display_message(message)


# Zone de saisie
user_input = st.chat_input("Tapez votre message...")


if user_input:
    # Ajouter le message utilisateur
    user_message = {
        "role": "user",
        "content": user_input,
        "created_at": None
    }
    st.session_state.messages.append(user_message)
    
    # Afficher le message immédiatement
    with chat_container:
        chat_widget.display_message(user_message)
        
        # Indicateur de saisie
        with st.spinner("🤖 L'assistant réfléchit..."):
            # Appeler l'API
            async def get_response():
                return await api_client.send_message(
                    message=user_input,
                    conversation_id=st.session_state.conversation_id,
                    context_token=st.session_state.context_token,
                    user_info=user_info
                )
            
            response_data = asyncio.run(get_response())
            
            if response_data:
                # Sauvegarder l'ID de conversation
                st.session_state.conversation_id = response_data.get('conversation_id')
                
                # Ajouter la réponse de l'assistant
                assistant_message = response_data.get('response')
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": assistant_message.get('content'),
                    "created_at": assistant_message.get('created_at')
                })
                
                # Afficher la réponse
                chat_widget.display_message(st.session_state.messages[-1])
                
                # Afficher les liens suggérés
                if response_data.get('suggested_links'):
                    chat_widget.display_suggested_links(response_data['suggested_links'])
                
                # Si escalade nécessaire
                if response_data.get('needs_escalation'):
                    st.warning("⚠️ Votre demande a été transférée à un conseiller. Un ticket a été créé.")
            else:
                st.error("❌ Erreur lors de l'envoi du message. Veuillez réessayer.")
    
    # Recharger pour afficher les nouveaux messages
    st.rerun()


# Bouton pour nouvelle conversation
if st.button("🔄 Nouvelle conversation"):
    from utils.session_manager import reset_conversation
    reset_conversation()
    st.rerun()
5.10 Fichier apps/frontend/pages/06_🎫_Tickets.py
python
import streamlit as st
import asyncio
import pandas as pd
from datetime import datetime
from utils.api_client import APIClient


st.title("🎫 Mes Tickets")


api_client = APIClient()


# Filtres
col1, col2, col3 = st.columns(3)


with col1:
    status_filter = st.selectbox(
        "Statut",
        ["Tous", "OPEN", "IN_PROGRESS", "RESOLVED", "CLOSED"]
    )


with col2:
    priority_filter = st.selectbox(
        "Priorité",
        ["Toutes", "LOW", "MEDIUM", "HIGH", "URGENT"]
    )


with col3:
    sort_by = st.selectbox(
        "Trier par",
        ["Date (récent)", "Date (ancien)", "Priorité"]
    )


# Récupérer les tickets
async def fetch_tickets():
    status = None if status_filter == "Tous" else status_filter
    return await api_client.get_tickets(status=status)


tickets = asyncio.run(fetch_tickets())


if not tickets:
    st.info("📭 Aucun ticket trouvé")
else:
    # Filtrer par priorité
    if priority_filter != "Toutes":
        tickets = [t for t in tickets if t.get('priority') == priority_filter]
    
    # Trier
    if sort_by == "Date (récent)":
        tickets.sort(key=lambda x: x.get('created_at', ''), reverse=True)
    elif sort_by == "Date (ancien)":
        tickets.sort(key=lambda x: x.get('created_at', ''))
    elif sort_by == "Priorité":
        priority_order = {'URGENT': 0, 'HIGH': 1, 'MEDIUM': 2, 'LOW': 3}
        tickets.sort(key=lambda x: priority_order.get(x.get('priority', 'LOW'), 999))
    
    # Afficher les tickets
    st.markdown(f"**{len(tickets)} ticket(s) trouvé(s)**")
    
    for ticket in tickets:
        with st.expander(
            f"🎫 Ticket #{ticket['id'][:8]} - {ticket.get('category', 'Général')} "
            f"({ticket.get('status', 'OPEN')})"
        ):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"**Statut:** {ticket.get('status', 'N/A')}")
                st.write(f"**Priorité:** {ticket.get('priority', 'N/A')}")
                st.write(f"**Catégorie:** {ticket.get('category', 'N/A')}")
            
            with col2:
                created_at = datetime.fromisoformat(ticket['created_at'].replace('Z', '+00:00'))
                st.write(f"**Créé le:** {created_at.strftime('%d/%m/%Y à %H:%M')}")
                
                if ticket.get('resolved_at'):
                    resolved_at = datetime.fromisoformat(ticket['resolved_at'].replace('Z', '+00:00'))
                    st.write(f"**Résolu le:** {resolved_at.strftime('%d/%m/%Y à %H:%M')}")
            
            if ticket.get('resolution_notes'):
                st.markdown("**Notes de résolution:**")
                st.info(ticket['resolution_notes'])
            
            # Bouton pour voir la conversation
            if st.button(f"Voir la conversation", key=f"view_{ticket['id']}"):
                st.session_state.conversation_id = ticket.get('conversation_id')
                st.switch_page
Continuer
python
               st.switch_page("pages/02_💬_Chat_Support.py")
5.11 Fichier apps/frontend/pages/03_📊_Analytics.py
python
import streamlit as st
import asyncio
from datetime import datetime, timedelta
from components.analytics_charts import AnalyticsCharts
from utils.api_client import APIClient


st.title("📊 Analytics & Statistiques")


api_client = APIClient()


# Sélecteur de période
col1, col2 = st.columns(2)


with col1:
    start_date = st.date_input(
        "Date de début",
        value=datetime.now() - timedelta(days=30)
    )


with col2:
    end_date = st.date_input(
        "Date de fin",
        value=datetime.now()
    )


# Bouton de rafraîchissement
if st.button("🔄 Actualiser les données"):
    st.rerun()


# Récupérer les analytics
async def fetch_analytics():
    return await api_client.get_analytics(
        start_date=start_date.isoformat(),
        end_date=end_date.isoformat()
    )


analytics_data = asyncio.run(fetch_analytics())


if not analytics_data:
    st.error("❌ Impossible de charger les données")
    st.stop()


# Afficher les KPI
st.markdown("### 📈 Indicateurs clés")
AnalyticsCharts.render_kpi_cards(analytics_data.get('kpis', {}))


st.markdown("---")


# Graphiques principaux
col1, col2 = st.columns(2)


with col1:
    st.markdown("### 📅 Évolution des conversations")
    AnalyticsCharts.render_conversations_chart(
        analytics_data.get('conversations_timeline', [])
    )


with col2:
    st.markdown("### 🎯 Types de demandes")
    AnalyticsCharts.render_intent_distribution(
        analytics_data.get('intent_distribution', {})
    )


st.markdown("---")


col1, col2 = st.columns(2)


with col1:
    st.markdown("### 🎫 Statut des tickets")
    AnalyticsCharts.render_ticket_status_chart(
        analytics_data.get('ticket_status', {})
    )


with col2:
    st.markdown("### 😊 Satisfaction client")
    AnalyticsCharts.render_satisfaction_gauge(
        analytics_data.get('satisfaction_score', 85.0)
    )


st.markdown("---")


# Activité horaire
st.markdown("### 🕐 Activité par heure")
AnalyticsCharts.render_hourly_activity(
    analytics_data.get('hourly_activity', [])
)


# Tableau des performances
st.markdown("### 📋 Performances détaillées")


performance_data = analytics_data.get('performance', {})


col1, col2, col3 = st.columns(3)


with col1:
    st.metric(
        "Messages totaux",
        performance_data.get('total_messages', 0)
    )


with col2:
    st.metric(
        "Temps moyen de résolution",
        f"{performance_data.get('avg_resolution_time', 0):.1f} min"
    )


with col3:
    st.metric(
        "Taux d'escalade",
        f"{performance_data.get('escalation_rate', 0):.1f}%"
    )
5.12 Fichier apps/frontend/static/css/custom.css
css
/* Style personnalisé pour l'application */


/* Variables de couleurs Free Mobile */
:root {
    --free-red: #d20000;
    --free-dark: #1a1a1a;
    --free-gray: #f5f5f5;
    --free-green: #02ab21;
}


/* Container principal */
.main {
    padding: 2rem;
}


/* Boutons personnalisés */
.stButton > button {
    background-color: var(--free-red);
    color: white;
    border-radius: 8px;
    padding: 0.5rem 2rem;
    font-weight: 600;
    border: none;
    transition: all 0.3s ease;
}


.stButton > button:hover {
    background-color: #b00000;
    box-shadow: 0 4px 8px rgba(210, 0, 0, 0.3);
    transform: translateY(-2px);
}


/* Messages du chat */
.stChatMessage {
    border-radius: 12px;
    padding: 1rem;
    margin-bottom: 1rem;
}


/* Zone de saisie du chat */
.stChatInput > div > div {
    border-radius: 24px;
    border: 2px solid #e0e0e0;
}


.stChatInput > div > div:focus-within {
    border-color: var(--free-red);
    box-shadow: 0 0 0 2px rgba(210, 0, 0, 0.1);
}


/* Cartes métriques */
.css-1r6slb0 {
    background-color: white;
    border-radius: 12px;
    padding: 1.5rem;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
}


/* Expanders */
.streamlit-expanderHeader {
    background-color: var(--free-gray);
    border-radius: 8px;
    padding: 0.75rem;
    font-weight: 600;
}


/* Formulaires */
.stTextInput > div > div > input,
.stSelectbox > div > div,
.stDateInput > div > div > input {
    border-radius: 8px;
    border: 1px solid #e0e0e0;
    padding: 0.75rem;
}


.stTextInput > div > div > input:focus,
.stSelectbox > div > div:focus-within,
.stDateInput > div > div > input:focus {
    border-color: var(--free-red);
    box-shadow: 0 0 0 2px rgba(210, 0, 0, 0.1);
}


/* Alertes personnalisées */
.stAlert {
    border-radius: 8px;
    border-left: 4px solid;
}


/* Success */
.stSuccess {
    border-left-color: var(--free-green);
    background-color: rgba(2, 171, 33, 0.05);
}


/* Warning */
.stWarning {
    border-left-color: #ffd93d;
    background-color: rgba(255, 217, 61, 0.05);
}


/* Error */
.stError {
    border-left-color: var(--free-red);
    background-color: rgba(210, 0, 0, 0.05);
}


/* Info */
.stInfo {
    border-left-color: #3498db;
    background-color: rgba(52, 152, 219, 0.05);
}


/* Tabs */
.stTabs [data-baseweb="tab-list"] {
    gap: 8px;
}


.stTabs [data-baseweb="tab"] {
    border-radius: 8px 8px 0 0;
    padding: 0.75rem 1.5rem;
}


/* Spinner */
.stSpinner > div {
    border-top-color: var(--free-red) !important;
}


/* Sidebar */
.css-1d391kg {
    background-color: var(--free-gray);
}


/* Headers */
h1, h2, h3 {
    color: var(--free-dark);
    font-weight: 700;
}


/* Liens */
a {
    color: var(--free-red);
    text-decoration: none;
}


a:hover {
    text-decoration: underline;
}


/* Tables */
.dataframe {
    border-radius: 8px;
    overflow: hidden;
}


/* Progress bar */
.stProgress > div > div {
    background-color: var(--free-red);
}
PARTIE 6 : DOCKER & INFRASTRUCTURE
6.1 Fichier infrastructure/docker/docker-compose.yml
yaml
version: '3.8'


services:
  # Frontend Streamlit
  frontend:
    build:
      context: ../../apps/frontend
      dockerfile: Dockerfile
    container_name: freemobile-frontend
    ports:
      - "8501:8501"
    environment:
      - BACKEND_API_URL=http://backend:8000
    volumes:
      - ../../apps/frontend:/app
      - frontend-data:/app/data
    depends_on:
      - backend
      - redis
    networks:
      - freemobile-network
    restart: unless-stopped


  # Backend FastAPI
  backend:
    build:
      context: ../../apps/backend
      dockerfile: Dockerfile
    container_name: freemobile-backend
    ports:
      - "8000:8000"
    environment:
      - USE_SUPABASE=${USE_SUPABASE:-false}
      - POSTGRES_LOCAL_HOST=postgres
      - POSTGRES_LOCAL_PORT=5432
      - POSTGRES_LOCAL_USER=${POSTGRES_LOCAL_USER}
      - POSTGRES_LOCAL_PASSWORD=${POSTGRES_LOCAL_PASSWORD}
      - POSTGRES_LOCAL_DB=${POSTGRES_LOCAL_DB}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - AI_ENGINE_URL=http://ai-engine:8001
      - SECRET_KEY=${SECRET_KEY}
    volumes:
      - ../../apps/backend:/app
    depends_on:
      - postgres
      - redis
      - ai-engine
    networks:
      - freemobile-network
    restart: unless-stopped


  # AI Engine
  ai-engine:
    build:
      context: ../../apps/ai-engine
      dockerfile: Dockerfile
    container_name: freemobile-ai-engine
    ports:
      - "8001:8001"
    environment:
      - LLM_MODEL_NAME=${LLM_MODEL_NAME}
      - LLM_TEMPERATURE=${LLM_TEMPERATURE}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS}
      - LLM_DEVICE=${LLM_DEVICE:-cpu}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - VECTOR_STORE_PATH=/app/data/vector_store
    volumes:
      - ../../apps/ai-engine:/app
      - ../../data:/app/data
      - ai-models:/root/.cache/huggingface
    networks:
      - freemobile-network
    restart: unless-stopped
    # Pour GPU (optionnel)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]


  # Social Monitor (Mastodon)
  social-monitor:
    build:
      context: ../../apps/social-monitor
      dockerfile: Dockerfile
    container_name: freemobile-social-monitor
    ports:
      - "8002:8002"
    environment:
      - MASTODON_INSTANCE_URL=${MASTODON_INSTANCE_URL}
      - MASTODON_CLIENT_ID=${MASTODON_CLIENT_ID}
      - MASTODON_CLIENT_SECRET=${MASTODON_CLIENT_SECRET}
      - MASTODON_ACCESS_TOKEN=${MASTODON_ACCESS_TOKEN}
      - MASTODON_MONITOR_HASHTAGS=${MASTODON_MONITOR_HASHTAGS}
      - BACKEND_API_URL=http://backend:8000
      - FRONTEND_URL=http://localhost:8501
    volumes:
      - ../../apps/social-monitor:/app
    depends_on:
      - backend
    networks:
      - freemobile-network
    restart: unless-stopped


  # PostgreSQL
  postgres:
    image: postgres:15-alpine
    container_name: freemobile-postgres
    environment:
      - POSTGRES_USER=${POSTGRES_LOCAL_USER}
      - POSTGRES_PASSWORD=${POSTGRES_LOCAL_PASSWORD}
      - POSTGRES_DB=${POSTGRES_LOCAL_DB}
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ../../scripts/init_db.sql:/docker-entrypoint-initdb.d/init.sql
    networks:
      - freemobile-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_LOCAL_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5


  # Redis
  redis:
    image: redis:7-alpine
    container_name: freemobile-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - freemobile-network
    restart: unless-stopped
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5


  # PgAdmin (optionnel, pour gérer PostgreSQL)
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: freemobile-pgadmin
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@freemobile.local
      - PGADMIN_DEFAULT_PASSWORD=admin123
    ports:
      - "5050:80"
    volumes:
      - pgadmin-data:/var/lib/pgadmin
    networks:
      - freemobile-network
    restart: unless-stopped
    profiles:
      - tools


networks:
  freemobile-network:
    driver: bridge


volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  pgadmin-data:
    driver: local
  frontend-data:
    driver: local
  ai-models:
    driver: local
6.2 Fichier apps/frontend/Dockerfile
dockerfile
FROM python:3.10-slim


# Définir le répertoire de travail
WORKDIR /app


# Installer les dépendances système
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    software-properties-common \
    git \
    && rm -rf /var/lib/apt/lists/*


# Copier les fichiers requirements
COPY requirements.txt .


# Installer les dépendances Python
RUN pip install --no-cache-dir -r requirements.txt


# Copier le code de l'application
COPY . .


# Exposer le port Streamlit
EXPOSE 8501


# Healthcheck
HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health


# Commande de démarrage
ENTRYPOINT ["streamlit", "run", "app.py", "--server.port=8501", "--server.address=0.0.0.0"]
6.3 Fichier apps/backend/Dockerfile
dockerfile
FROM python:3.10-slim


WORKDIR /app


# Installer les dépendances système
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*


# Copier les fichiers requirements
COPY requirements.txt .


# Installer les dépendances Python
RUN pip install --no-cache-dir -r requirements.txt


# Copier le code de l'application
COPY . .


# Exposer le port
EXPOSE 8000


# Healthcheck
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1


# Commande de démarrage
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
6.4 Fichier apps/ai-engine/Dockerfile
dockerfile
FROM python:3.10-slim


WORKDIR /app


# Installer les dépendances système
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    git \
    && rm -rf /var/lib/apt/lists/*


# Copier les fichiers requirements
COPY requirements.txt .


# Installer les dépendances Python
RUN pip install --no-cache-dir -r requirements.txt


# Copier le code de l'application
COPY . .


# Créer les dossiers nécessaires
RUN mkdir -p /app/data/vector_store


# Exposer le port
EXPOSE 8001


# Healthcheck
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8001/ || exit 1


# Commande de démarrage
CMD ["python", "-m", "uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8001"]
6.5 Fichier apps/social-monitor/Dockerfile
dockerfile
FROM python:3.10-slim


WORKDIR /app


# Installer les dépendances système
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*


# Copier les fichiers requirements
COPY requirements.txt .


# Installer les dépendances Python
RUN pip install --no-cache-dir -r requirements.txt


# Copier le code de l'application
COPY . .


# Exposer le port
EXPOSE 8002


# Commande de démarrage
CMD ["python", "main.py"]
PARTIE 7 : DONNÉES D'ENTRAÎNEMENT
7.1 Structure du dossier data/
data/
├── raw/
│   ├── faqs/
│   │   ├── facturation.json
│   │   ├── technique.json
│   │   ├── forfait.json
│   │   └── resiliation.json
│   ├── conversations/
│   │   └── historical_chats.csv
│   └── documentation/
│       ├── free_mobile_guide.pdf
│       └── sav_procedures.md
├── processed/
│   ├── embeddings/
│   ├── training_set.jsonl
│   └── validation_set.jsonl
├── vector_store/
└── scripts/
    ├── prepare_dataset.py
    ├── generate_embeddings.py
    └── load_to_vectorstore.py
7.2 Fichier data/raw/faqs/facturation.json
json
[
  {
    "question": "Comment consulter ma facture Free Mobile ?",
    "answer": "Vous pouvez consulter votre facture Free Mobile de plusieurs façons :\n1. Connectez-vous à votre Espace Abonné sur mobile.free.fr\n2. Cliquez sur 'Mes factures' dans le menu\n3. Vous pouvez également télécharger vos factures au format PDF\n\nVos factures sont disponibles pendant 12 mois.",
    "category": "facturation",
    "tags": ["facture", "consultation", "espace client"]
  },
  {
    "question": "Quel est le montant de mon forfait Free Mobile ?",
    "answer": "Free Mobile propose plusieurs forfaits :\n- Forfait Free 2€ : 2€/mois avec 2h d'appels et 50 SMS/MMS\n- Forfait Free 5G : 19,99€/mois (15,99€ pour les abonnés Freebox) avec appels/SMS/MMS illimités et 300 Go de data 5G\n\nLe montant exact dépend de votre abonnement. Consultez votre Espace Abonné pour voir votre forfait actuel.",
    "category": "facturation",
    "tags": ["forfait", "prix", "montant"]
  },
  {
    "question": "Comment modifier mon moyen de paiement ?",
    "answer": "Pour modifier votre moyen de paiement :\n1. Connectez-vous à votre Espace Abonné\n2. Allez dans 'Mon compte' > 'Moyen de paiement'\n3. Cliquez sur 'Modifier'\n4. Entrez vos nouvelles coordonnées bancaires\n5. Validez la modification\n\nLa modification sera effective pour votre prochaine facture.",
    "category": "facturation",
    "tags": ["paiement", "carte bancaire", "prélèvement"]
  },
  {
    "question": "Pourquoi ma facture est-elle plus élevée ce mois-ci ?",
    "answer": "Plusieurs raisons peuvent expliquer une facture plus élevée :\n- Dépassement de votre forfait data\n- Appels vers des numéros surtaxés\n- Options additionnelles activées\n- Frais de mise en service (premier mois)\n- Communications depuis l'étranger\n\nConsultez le détail de votre facture dans votre Espace Abonné pour identifier les consommations supplémentaires.",
    "category": "facturation",
    "tags": ["facture élevée", "surcoût", "dépassement"]
  },
  {
    "question": "Comment contester une facture ?",
    "answer": "Pour contester une facture :\n1. Identifiez précisément les lignes contestées sur votre facture\n2. Connectez-vous à votre Espace Abonné\n3. Allez dans 'Assistance' > 'Nous contacter'\n4. Sélectionnez 'Facturation' puis 'Contestation de facture'\n5. Détaillez votre réclamation avec les éléments justificatifs\n\nVous recevrez une réponse sous 10 jours ouvrés. En attendant le traitement, votre facture reste exigible.",
    "category": "facturation",
    "tags": ["contestation", "réclamation", "litige"]
  }
]
7.3 Fichier data/raw/faqs/technique.json
json
[
  {
    "question": "Je n'ai pas de réseau, que faire ?",
    "answer": "Si vous n'avez pas de réseau :\n1. Vérifiez que le mode Avion est désactivé\n2. Redémarrez votre téléphone\n3. Vérifiez que votre carte SIM est bien insérée\n4. Vérifiez la couverture réseau Free Mobile dans votre zone sur mobile.free.fr\n5. Testez en retirant et réinsérant la carte SIM\n\nSi le problème persiste, contactez le service client.",
    "category": "technique",
    "tags": ["réseau", "signal", "couverture"]
  },
  {
    "question": "Comment configurer les APN Free Mobile ?",
    "answer": "Configuration APN Free Mobile :\n- Nom : Free\n- APN : free\n- Proxy : Non défini\n- Port : Non défini\n- Nom d'utilisateur : Non défini\n- Mot de passe : Non défini\n- Serveur : Non défini\n- MMSC : http://mms.free.fr\n- Proxy MMS : Non défini\n- Port MMS : Non défini\n- MCC : 208\n- MNC : 15\n- Type d'authentification : Non défini\n- Type d'APN : default,supl,mms\n\nRedémarrez votre téléphone après configuration.",
    "category": "technique",
    "tags": ["APN", "configuration", "internet", "data"]
  },
  {
    "question": "Ma connexion Internet est lente, pourquoi ?",
    "answer": "Plusieurs facteurs peuvent ralentir votre connexion :\n- Vous avez dépassé votre enveloppe data (débit réduit)\n- Zone de faible couverture réseau\n- Saturation du réseau (heures de pointe)\n- Problème de configuration APN\n- Limitation de votre appareil (pas compatible 4G/5G)\n\nVérifiez votre consommation data dans votre Espace Abonné et testez à différents endroits.",
    "category": "technique",
    "tags": ["lenteur", "débit", "internet", "4g", "5g"]
  },
  {
    "question": "Comment activer la 5G sur mon forfait Free ?",
    "answer": "Pour activer la 5G :\n1. Vérifiez que vous avez le forfait Free 5G (19,99€/mois)\n2. Votre téléphone doit être compatible 5G\n3. Connectez-vous à votre Espace Abonné\n4. Allez dans 'Options' > 'Réseau'\n5. Activez l'option '5G'\n\nLa 5G est activée automatiquement sur le forfait Free 5G. Assurez-vous d'être dans une zone couverte par la 5G Free.",
    "category": "technique",
    "tags": ["5g", "activation", "réseau"]
  },
  {
    "question": "Je ne peux pas envoyer de MMS, que faire ?",
    "answer": "Si vous ne pouvez pas envoyer de MMS :\n1. Vérifiez que les données mobiles sont activées\n2. Configurez correctement les APN Free (voir question APN)\n3. Vérifiez que le MMSC est bien configuré : http://mms.free.fr\n4. Redémarrez votre téléphone\n5. Testez en désactivant le WiFi\n\nLes MMS nécessitent une connexion data active.",
    "category": "technique",
    "tags": ["mms", "message", "envoi"]
  }
]
7.4 Fichier data/raw/faqs/forfait.json
json
[
  {
    "question": "Comment changer de forfait Free Mobile ?",
    "answer": "Pour changer de forfait :\n1. Connectez-vous à votre Espace Abonné sur mobile.free.fr\n2. Cliquez sur 'Mon forfait' puis 'Changer de forfait'\n3. Choisissez le nouveau forfait souhaité\n4. Validez le changement\n\nLe changement est effectif immédiatement et la nouvelle tarification s'applique au prorata sur la prochaine facture.",
    "category": "forfait",
    "tags": ["changement", "forfait", "migration"]
  },
  {
    "question": "Quelles sont les options disponibles sur Free Mobile ?",
    "answer": "Free Mobile propose plusieurs options :\n- Appels illimités vers les fixes et mobiles en Europe et DOM\n- Data supplémentaire lors de voyages à l'étranger\n- Blocage des communications vers certains numéros\n- Option multi-SIM (jusqu'à 3 SIM supplémentaires)\n\nConsultez votre Espace Abonné > Options pour voir toutes les options disponibles pour votre forfait.",
    "category": "forfait",
    "tags": ["options", "services", "suppléments"]
  },
  {
    "question": "Comment suivre ma consommation data ?",
    "answer": "Plusieurs moyens de suivre votre consommation :\n1. Dans votre Espace Abonné : section 'Suivi conso'\n2. Par SMS : envoyez 'CONSO' au 555 (gratuit)\n3. Application Free Mobile (iOS/Android)\n\nVous recevez également des alertes SMS à 50%, 80% et 100% de consommation.",
    "category": "forfait",
    "tags": ["consommation", "data", "suivi"]
  },
  {
    "question": "Que se passe-t-il si je dépasse mon forfait data ?",
    "answer": "En cas de dépassement du forfait data :\n- Forfait 2€ : débit réduit automatiquement\n- Forfait 5G : data au-delà de 300 Go réduite (débit limité)\n\nVous pouvez acheter des recharges data dans votre Espace Abonné ou attendre le renouvellement mensuel de votre forfait.",
    "category": "forfait",
    "tags": ["dépassement", "data", "hors forfait"]
  },
  {
    "question": "Comment activer le roaming à l'étranger ?",
    "answer": "Le roaming est automatiquement inclus dans les forfaits Free Mobile :\n- Forfait 2€ : appels/SMS/MMS en Europe et DOM inclus (hors data)\n- Forfait 5G : 25 Go de data utilisables en Europe/DOM + appels/SMS illimités\n\nPour activer :\n1. Vérifiez que le roaming est activé dans les paramètres de votre téléphone\n2. Sélectionnez un réseau partenaire à l'arrivée\n\nConsultez mobile.free.fr pour les tarifs hors Europe.",
    "category": "forfait",
    "tags": ["roaming", "étranger", "international"]
  }
]
7.5 Fichier data/raw/faqs/resiliation.json
json
[
  {
    "question": "Comment résilier mon forfait Free Mobile ?",
    "answer": "Pour résilier votre forfait Free Mobile :\n1. Connectez-vous à votre Espace Abonné\n2. Allez dans 'Mon compte' > 'Résilier mon forfait'\n3. Suivez les étapes de résiliation\n4. Confirmez votre demande\n\nVotre ligne sera résiliée sous 48h. Aucun frais de résiliation ne vous sera facturé. Vous pouvez également envoyer un courrier recommandé.",
    "category": "resiliation",
    "tags": ["résiliation", "arrêt", "clôture"]
  },
  {
    "question": "Dois-je renvoyer ma carte SIM après résiliation ?",
    "answer": "Non, vous n'avez pas besoin de renvoyer votre carte SIM Free Mobile après résiliation. Vous pouvez simplement la détruire.\n\nSi vous souhaitez conserver votre numéro chez un autre opérateur, conservez la SIM active jusqu'à la portabilité complète.",
    "category": "resiliation",
    "tags": ["sim", "résiliation", "retour"]
  },
  {
    "question": "Puis-je conserver mon numéro en quittant Free ?",
    "answer": "Oui, vous pouvez conserver votre numéro grâce à la portabilité :\n1. Demandez un code RIO en appelant le 3179 (gratuit)\n2. Communiquez ce code RIO à votre nouvel opérateur\n3. Ne résiliez PAS votre ligne Free avant
Continuer
json
3. Ne résiliez PAS votre ligne Free avant la portabilité
4. La résiliation sera automatique lors du transfert du numéro


Le transfert prend généralement 1 à 3 jours ouvrés.",
    "category": "resiliation",
    "tags": ["portabilité", "rio", "numéro", "conservation"]
  },
  {
    "question": "Y a-t-il des frais de résiliation chez Free Mobile ?",
    "answer": "Non, Free Mobile ne facture aucun frais de résiliation. Les forfaits Free Mobile sont sans engagement, vous pouvez résilier à tout moment gratuitement.\n\nVous serez facturé au prorata du mois en cours jusqu'à la date effective de résiliation.",
    "category": "resiliation",
    "tags": ["frais", "résiliation", "coût"]
  },
  {
    "question": "Comment obtenir mon code RIO ?",
    "answer": "Pour obtenir votre code RIO Free Mobile :\n1. Appelez le 3179 depuis votre mobile Free (gratuit)\n2. Vous recevrez immédiatement votre code RIO par SMS\n3. Vous pouvez aussi le consulter dans votre Espace Abonné\n\nLe code RIO est valable 4 mois et permet de conserver votre numéro lors d'un changement d'opérateur.",
    "category": "resiliation",
    "tags": ["rio", "code", "portabilité"]
  }
]
7.6 Fichier data/raw/documentation/sav_procedures.md
markdown
# Procédures SAV Free Mobile


## 1. Procédure de Premier Contact


### 1.1 Accueil du client
- Saluer poliment le client
- Identifier la source de contact (web, Mastodon, autre)
- Recueillir les informations essentielles :
  - Nom et prénom
  - Numéro de téléphone
  - Email (optionnel)


### 1.2 Qualification de la demande
Catégoriser la demande selon :
- **Facturation** : questions sur factures, paiements, montants
- **Technique** : problèmes de réseau, configuration, panne
- **Forfait** : changement de forfait, options, consommation
- **Résiliation** : demande d'arrêt de service, portabilité
- **Réclamation** : insatisfaction, litige, problème non résolu


### 1.3 Niveau d'urgence
- **LOW** : Question simple, information
- **MEDIUM** : Problème gênant mais non bloquant
- **HIGH** : Service partiellement indisponible
- **URGENT** : Service totalement indisponible, impact critique


## 2. Résolution de Premier Niveau (Chatbot)


### 2.1 Demandes traitables automatiquement
Le chatbot peut traiter :
- Consultation de factures
- Suivi de consommation
- Configuration APN
- Questions FAQ standards
- Procédures simples


### 2.2 Réponses types
Utiliser le système RAG pour fournir :
- Réponses précises basées sur la documentation
- Liens vers l'Espace Abonné
- Tutoriels étape par étape
- Numéros et contacts utiles


### 2.3 Détection d'escalade
Escalader vers un humain si :
- Demande de résiliation
- Réclamation complexe
- Litige financier
- Problème technique non résolu après 3 tentatives
- Demande explicite de contact humain
- Sentiment négatif intense détecté


## 3. Escalade vers Agent Humain


### 3.1 Création de ticket
Lors d'une escalade, créer automatiquement un ticket avec :
- ID conversation
- Résumé du problème
- Historique complet des échanges
- Catégorie et priorité
- Informations client


### 3.2 Notification agent
Notifier immédiatement :
- Agent disponible en temps réel
- Sinon, notification par email
- Affichage dans le tableau de bord


### 3.3 Prise en charge
L'agent doit :
- Accuser réception sous 15 minutes
- Lire l'historique complet
- Contacter le client dans le délai indiqué selon priorité :
  - URGENT : 1 heure
  - HIGH : 4 heures
  - MEDIUM : 24 heures
  - LOW : 48 heures


## 4. Gestion des Réclamations Mastodon


### 4.1 Détection
Le système surveille :
- Hashtags : #Free, #FreeMobile, #SAVFree
- Mentions du compte officiel
- Mots-clés de réclamation


### 4.2 Analyse automatique
- Sentiment : positif, neutre, négatif
- Urgence : selon intensité émotionnelle
- Type de problème : classification automatique


### 4.3 Réponse publique
Toujours répondre publiquement :
- Message de prise en compte
- Lien vers chatbot personnalisé
- Délai de traitement indicatif
- Hashtags #SAVFree #Support


### 4.4 Suivi privé
- Redirection vers chatbot avec contexte
- Conversation privée préservant l'historique
- Ticket créé automatiquement si nécessaire


## 5. Métriques de Performance


### 5.1 KPI à surveiller
- Temps de première réponse
- Taux de résolution automatique
- Taux d'escalade
- Satisfaction client (CSAT)
- Net Promoter Score (NPS)


### 5.2 Objectifs
- Résolution automatique : > 70%
- Temps de réponse chatbot : < 3 secondes
- Temps de prise en charge humaine : < 15 minutes
- Taux de satisfaction : > 85%


## 6. Cas Spéciaux


### 6.1 Client agressif
- Rester professionnel et calme
- Ne pas prendre personnellement
- Escalader si nécessaire
- Documenter tous les échanges


### 6.2 Problème récurrent
- Vérifier l'historique client
- Identifier la cause racine
- Proposer solution définitive
- Compensation si approprié


### 6.3 Demande hors périmètre
- Expliquer poliment les limites
- Rediriger vers le bon service
- Fournir les contacts appropriés


## 7. Clôture et Suivi


### 7.1 Résolution
- S'assurer de la satisfaction client
- Résumer la solution appliquée
- Demander confirmation de résolution


### 7.2 Ticket fermé
- Marquer comme RESOLVED
- Ajouter notes de résolution
- Archiver la conversation


### 7.3 Enquête de satisfaction
- Envoyer automatiquement après clôture
- Noter sur 5 étoiles
- Champ commentaire libre
- Analyser les retours


## 8. Formation Continue


### 8.1 Mise à jour base de connaissances
- Ajouter nouveaux cas
- Corriger informations obsolètes
- Enrichir FAQ


### 8.2 Amélioration du chatbot
- Analyser conversations
- Identifier points de friction
- Affiner modèle IA
- Optimiser prompts
7.7 Fichier data/scripts/prepare_dataset.py
python
#!/usr/bin/env python3
"""
Script pour préparer les datasets d'entraînement
Convertit les FAQs et documentations en format JSONL pour le fine-tuning
"""


import json
import os
from pathlib import Path
from typing import List, Dict, Any
import PyPDF2
import random


class DatasetPreparer:
    def __init__(self, raw_data_path: str = "./data/raw"):
        self.raw_data_path = Path(raw_data_path)
        self.processed_path = Path("./data/processed")
        self.processed_path.mkdir(parents=True, exist_ok=True)
    
    def load_faqs(self) -> List[Dict[str, Any]]:
        """Charge tous les fichiers FAQ"""
        all_faqs = []
        faq_path = self.raw_data_path / "faqs"
        
        if not faq_path.exists():
            print(f"⚠️  Dossier FAQs introuvable: {faq_path}")
            return all_faqs
        
        for faq_file in faq_path.glob("*.json"):
            print(f"📖 Chargement de {faq_file.name}")
            with open(faq_file, 'r', encoding='utf-8') as f:
                faqs = json.load(f)
                all_faqs.extend(faqs)
        
        print(f"✅ {len(all_faqs)} FAQs chargées")
        return all_faqs
    
    def faq_to_training_format(self, faq: Dict[str, Any]) -> Dict[str, Any]:
        """Convertit une FAQ au format d'entraînement"""
        return {
            "messages": [
                {
                    "role": "system",
                    "content": "Tu es un assistant virtuel du service client Free Mobile. Réponds de manière professionnelle et précise aux questions des clients."
                },
                {
                    "role": "user",
                    "content": faq["question"]
                },
                {
                    "role": "assistant",
                    "content": faq["answer"]
                }
            ],
            "metadata": {
                "category": faq.get("category", "general"),
                "tags": faq.get("tags", [])
            }
        }
    
    def create_training_variations(self, faq: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Crée des variations de la question pour augmenter le dataset"""
        variations = []
        base_training = self.faq_to_training_format(faq)
        variations.append(base_training)
        
        # Variations de formulation (exemples simplifiés)
        question_variations = [
            faq["question"],
            faq["question"].lower(),
            faq["question"].replace("?", ""),
            f"Pouvez-vous m'aider avec : {faq['question'].lower()}"
        ]
        
        for variation in question_variations[1:]:  # Skip the first one (original)
            variant = {
                "messages": [
                    {
                        "role": "system",
                        "content": base_training["messages"][0]["content"]
                    },
                    {
                        "role": "user",
                        "content": variation
                    },
                    {
                        "role": "assistant",
                        "content": faq["answer"]
                    }
                ],
                "metadata": base_training["metadata"]
            }
            variations.append(variant)
        
        return variations
    
    def split_train_validation(
        self,
        data: List[Dict[str, Any]],
        validation_ratio: float = 0.2
    ) -> tuple:
        """Sépare les données en ensemble d'entraînement et de validation"""
        random.shuffle(data)
        split_idx = int(len(data) * (1 - validation_ratio))
        
        training_set = data[:split_idx]
        validation_set = data[split_idx:]
        
        return training_set, validation_set
    
    def save_jsonl(self, data: List[Dict[str, Any]], filename: str):
        """Sauvegarde les données au format JSONL"""
        filepath = self.processed_path / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for item in data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')
        
        print(f"✅ Sauvegardé: {filepath} ({len(data)} exemples)")
    
    def prepare_all(self):
        """Prépare tous les datasets"""
        print("🚀 Préparation des datasets...")
        
        # Charger les FAQs
        faqs = self.load_faqs()
        
        if not faqs:
            print("❌ Aucune FAQ trouvée")
            return
        
        # Créer les variations
        all_training_data = []
        for faq in faqs:
            variations = self.create_training_variations(faq)
            all_training_data.extend(variations)
        
        print(f"📊 Total d'exemples avec variations: {len(all_training_data)}")
        
        # Séparer train/validation
        training_set, validation_set = self.split_train_validation(all_training_data)
        
        # Sauvegarder
        self.save_jsonl(training_set, "training_set.jsonl")
        self.save_jsonl(validation_set, "validation_set.jsonl")
        
        # Statistiques
        print("\n📊 Statistiques:")
        print(f"  - Entraînement: {len(training_set)} exemples")
        print(f"  - Validation: {len(validation_set)} exemples")
        
        # Répartition par catégorie
        categories = {}
        for item in all_training_data:
            cat = item['metadata']['category']
            categories[cat] = categories.get(cat, 0) + 1
        
        print("\n📈 Répartition par catégorie:")
        for cat, count in sorted(categories.items()):
            print(f"  - {cat}: {count}")
        
        print("\n✅ Préparation terminée!")


def main():
    preparer = DatasetPreparer()
    preparer.prepare_all()


if __name__ == "__main__":
    main()
7.8 Fichier data/scripts/load_to_vectorstore.py
python
#!/usr/bin/env python3
"""
Script pour charger les documents dans ChromaDB
"""


import sys
sys.path.append('../../apps/ai-engine')


from ai_engine.rag.vector_store import VectorStore
from ai_engine.rag.document_processor import DocumentProcessor
import logging


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main():
    logger.info("🚀 Chargement des documents dans la base vectorielle...")
    
    # Initialiser les composants
    vector_store = VectorStore()
    processor = DocumentProcessor(data_path="./data/raw")
    
    # Vérifier si la collection existe déjà
    current_count = vector_store.get_collection_count()
    
    if current_count > 0:
        response = input(f"⚠️  La base contient déjà {current_count} documents. Voulez-vous la réinitialiser? (o/n): ")
        if response.lower() == 'o':
            vector_store.delete_collection()
            vector_store = VectorStore()  # Recréer
            logger.info("✅ Base vectorielle réinitialisée")
    
    # Traiter tous les documents
    logger.info("📚 Traitement des documents...")
    documents = processor.process_all_documents()
    
    if not documents:
        logger.error("❌ Aucun document à traiter")
        return
    
    logger.info(f"📊 {len(documents)} documents trouvés")
    
    # Préparer les données pour ChromaDB
    doc_contents = [doc['content'] for doc in documents]
    metadatas = [doc['metadata'] for doc in documents]
    
    # Ajouter par batch pour éviter les problèmes de mémoire
    batch_size = 100
    total_added = 0
    
    for i in range(0, len(documents), batch_size):
        batch_contents = doc_contents[i:i+batch_size]
        batch_metadatas = metadatas[i:i+batch_size]
        
        vector_store.add_documents(batch_contents, batch_metadatas)
        total_added += len(batch_contents)
        
        logger.info(f"✅ Ajouté: {total_added}/{len(documents)} documents")
    
    # Statistiques finales
    final_count = vector_store.get_collection_count()
    
    logger.info("\n📊 Statistiques finales:")
    logger.info(f"  - Documents dans la base: {final_count}")
    
    # Répartition par type
    types = {}
    for doc in documents:
        doc_type = doc['metadata'].get('type', 'unknown')
        types[doc_type] = types.get(doc_type, 0) + 1
    
    logger.info("\n📈 Répartition par type:")
    for doc_type, count in sorted(types.items()):
        logger.info(f"  - {doc_type}: {count}")
    
    logger.info("\n✅ Chargement terminé!")
    
    # Test de recherche
    logger.info("\n🔍 Test de recherche...")
    test_query = "Comment consulter ma facture ?"
    results = vector_store.get_relevant_context(test_query, top_k=3)
    
    logger.info(f"\nRésultats pour '{test_query}':")
    for i, result in enumerate(results, 1):
        logger.info(f"\n  [{i}] Similarité: {result['similarity']:.2f}")
        logger.info(f"      Type: {result['metadata'].get('type')}")
        logger.info(f"      Contenu: {result['content'][:200]}...")


if __name__ == "__main__":
    main()
PARTIE 8 : SCRIPTS DE DÉPLOIEMENT
8.1 Fichier scripts/setup_dev.sh
bash
#!/bin/bash


# Script de configuration de l'environnement de développement
# Usage: ./scripts/setup_dev.sh


set -e


echo "🚀 Configuration de l'environnement de développement Free Mobile Chatbot"


# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color


# Vérifier Python
echo -e "\n${YELLOW}📦 Vérification de Python...${NC}"
if ! command -v python3 &> /dev/null; then
    echo -e "${RED}❌ Python 3 n'est pas installé${NC}"
    exit 1
fi


PYTHON_VERSION=$(python3 --version | cut -d' ' -f2 | cut -d'.' -f1-2)
echo -e "${GREEN}✅ Python $PYTHON_VERSION détecté${NC}"


# Vérifier Docker
echo -e "\n${YELLOW}🐳 Vérification de Docker...${NC}"
if ! command -v docker &> /dev/null; then
    echo -e "${RED}❌ Docker n'est pas installé${NC}"
    echo "Installez Docker depuis: https://docs.docker.com/get-docker/"
    exit 1
fi
echo -e "${GREEN}✅ Docker détecté${NC}"


# Vérifier Docker Compose
echo -e "\n${YELLOW}🐳 Vérification de Docker Compose...${NC}"
if ! command -v docker-compose &> /dev/null; then
    echo -e "${RED}❌ Docker Compose n'est pas installé${NC}"
    exit 1
fi
echo -e "${GREEN}✅ Docker Compose détecté${NC}"


# Créer les dossiers nécessaires
echo -e "\n${YELLOW}📁 Création de la structure des dossiers...${NC}"
mkdir -p data/{raw/{faqs,conversations,documentation},processed,vector_store,scripts}
mkdir -p apps/{frontend,backend,ai-engine,social-monitor}
mkdir -p tests/{unit,integration,fixtures}
mkdir -p docs
echo -e "${GREEN}✅ Structure créée${NC}"


# Copier .env.example vers .env
echo -e "\n${YELLOW}⚙️  Configuration de l'environnement...${NC}"
if [ ! -f .env ]; then
    cp .env.example .env
    echo -e "${GREEN}✅ Fichier .env créé${NC}"
    echo -e "${YELLOW}⚠️  N'oubliez pas de configurer vos variables d'environnement dans .env${NC}"
else
    echo -e "${YELLOW}⚠️  Le fichier .env existe déjà${NC}"
fi


# Installer les dépendances Python globales
echo -e "\n${YELLOW}📦 Installation des dépendances Python...${NC}"
if [ -f requirements.txt ]; then
    python3 -m pip install --upgrade pip
    pip install -r requirements.txt
    echo -e "${GREEN}✅ Dépendances installées${NC}"
fi


# Initialiser Git si nécessaire
echo -e "\n${YELLOW}📝 Initialisation Git...${NC}"
if [ ! -d .git ]; then
    git init
    echo -e "${GREEN}✅ Repository Git initialisé${NC}"
else
    echo -e "${YELLOW}⚠️  Git déjà initialisé${NC}"
fi


# Créer .gitignore si nécessaire
if [ ! -f .gitignore ]; then
    cat > .gitignore << 'EOF'
# Environment
.env
.env.local
*.env


# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg


# Virtual Environment
venv/
ENV/
env/


# IDE
.vscode/
.idea/
*.swp
*.swo
*~


# Data
data/raw/conversations/*.csv
data/processed/
data/vector_store/
*.db


# Logs
*.log
logs/


# Docker
docker-compose.override.yml


# OS
.DS_Store
Thumbs.db


# Models
*.pth
*.pt
*.bin
models/


# Secrets
*.secret
*.key
*.pem
EOF
    echo -e "${GREEN}✅ .gitignore créé${NC}"
fi


echo -e "\n${GREEN}🎉 Configuration de l'environnement terminée!${NC}"
echo -e "\n${YELLOW}Prochaines étapes:${NC}"
echo "1. Configurez vos variables d'environnement dans .env"
echo "2. Pour Mastodon: python scripts/setup_mastodon.py"
echo "3. Initialisez la base de données: python scripts/init_database.py local"
echo "4. Préparez les datasets: python data/scripts/prepare_dataset.py"
echo "5. Chargez les données dans ChromaDB: python data/scripts/load_to_vectorstore.py"
echo "6. Lancez l'application: docker-compose -f infrastructure/docker/docker-compose.yml up"
8.2 Fichier scripts/setup_mastodon.py
python
#!/usr/bin/env python3
"""
Script de configuration Mastodon
Crée l'application et obtient les tokens d'accès
"""


from mastodon import Mastodon
import os
from dotenv import load_dotenv, set_key


load_dotenv()


def setup_mastodon():
    print("🐘 Configuration de l'application Mastodon")
    print("=" * 50)
    
    instance_url = input("\n📍 URL de l'instance Mastodon (ex: https://mastodon.social): ").strip()
    
    if not instance_url:
        instance_url = "https://mastodon.social"
    
    print(f"\n✅ Instance: {instance_url}")
    
    # Étape 1: Créer l'application
    print("\n1️⃣  Création de l'application...")
    
    try:
        Mastodon.create_app(
            'Free Mobile SAV Bot',
            api_base_url=instance_url,
            to_file='mastodon_clientcred.secret',
            scopes=['read', 'write', 'follow']
        )
        print("✅ Application créée")
    except Exception as e:
        print(f"❌ Erreur lors de la création: {e}")
        return
    
    # Étape 2: Connexion pour obtenir le token
    print("\n2️⃣  Connexion à votre compte...")
    print("Vous devez vous connecter avec un compte Mastodon qui servira de bot.")
    
    email = input("Email Mastodon: ").strip()
    password = input("Mot de passe: ").strip()
    
    try:
        mastodon = Mastodon(
            client_id='mastodon_clientcred.secret',
            api_base_url=instance_url
        )
        
        access_token = mastodon.log_in(
            email,
            password,
            to_file='mastodon_usercred.secret',
            scopes=['read', 'write', 'follow']
        )
        
        print("✅ Connexion réussie")
        
        # Lire les credentials
        with open('mastodon_clientcred.secret', 'r') as f:
            lines = f.readlines()
            client_id = lines[0].strip()
            client_secret = lines[1].strip()
        
        # Mettre à jour .env
        print("\n3️⃣  Mise à jour du fichier .env...")
        
        env_file = '.env'
        set_key(env_file, 'MASTODON_INSTANCE_URL', instance_url)
        set_key(env_file, 'MASTODON_CLIENT_ID', client_id)
        set_key(env_file, 'MASTODON_CLIENT_SECRET', client_secret)
        set_key(env_file, 'MASTODON_ACCESS_TOKEN', access_token)
        
        print("✅ Fichier .env mis à jour")
        
        # Test de connexion
        print("\n4️⃣  Test de connexion...")
        
        mastodon_test = Mastodon(
            access_token=access_token,
            api_base_url=instance_url
        )
        
        account = mastodon_test.me()
        print(f"✅ Connecté en tant que: @{account['username']}")
        
        print("\n🎉 Configuration Mastodon terminée!")
        print("\n📝 Informations sauvegardées:")
        print(f"  - Instance: {instance_url}")
        print(f"  - Compte bot: @{account['username']}")
        print(f"  - Client ID: {client_id[:20]}...")
        print(f"  - Access Token: {access_token[:20]}...")
        
        print("\n⚠️  IMPORTANT:")
        print("  - Les fichiers *.secret contiennent vos credentials")
        print("  - NE PAS les commiter sur Git")
        print("  - Ils sont déjà dans .gitignore")
        
    except Exception as e:
        print(f"❌ Erreur lors de la connexion: {e}")
        print("\nVérifiez:")
        print("  - Votre email et mot de passe")
        print("  - Que l'instance Mastodon est accessible")


if __name__ == "__main__":
    setup_mastodon()
8.3 Fichier scripts/deploy.sh
bash
#!/bin/bash


# Script de déploiement
# Usage: ./scripts/deploy.sh [environment]
# Environments: local, staging, production


set -e


ENVIRONMENT=${1:-local}


echo "🚀 Déploiement de l'application - Environnement: $ENVIRONMENT"


# Couleurs
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'


case $ENVIRONMENT in
  local)
    echo -e "${YELLOW}📦 Déploiement local avec Docker Compose...${NC}"
    
    # Arrêter les containers existants
    echo "🛑 Arrêt des containers existants..."
    docker-compose -f infrastructure/docker/docker-compose.yml down
    
    # Construire les images
    echo "🏗️  Construction des images Docker..."
    docker-compose -f infrastructure/docker/docker-compose.yml build
    
    # Démarrer les services
    echo "▶️  Démarrage des services..."
    docker-compose -f infrastructure/docker/docker-compose.yml up -d
    
    # Attendre que les services soient prêts
    echo "⏳ Attente du démarrage des services..."
    sleep 10
    
    # Vérifier le statut
    echo -e "\n${GREEN}✅ Services démarrés:${NC}"
    docker-compose -f infrastructure/docker/docker-compose.yml ps
    
    echo -e "\n${GREEN}🌐 URLs d'accès:${NC}"
    echo "  - Frontend: http://localhost:8501"
    echo "  - Backend API: http://localhost:8000"
    echo "  - AI Engine: http://localhost:8001"
    echo "  - PgAdmin: http://localhost:5050"
    ;;
    
  staging|production)
    echo -e "${RED}❌ Déploiement $ENVIRONMENT non implémenté${NC}"
    echo "Pour déployer en $ENVIRONMENT, configurez votre CI/CD"
    exit 1
    ;;
    
  *)
    echo -e "${RED}❌ Environnement invalide: $ENVIRONMENT${NC}"
    echo "Usage: ./scripts/deploy.sh [local|staging|production]"
    exit 1
    ;;
esac


echo -e "\n${GREEN}✅ Déploiement terminé!${NC}"
Voulez-vous que je continue avec la dernière partie :
* Configuration Supabase
* README.md complet
* Guide de contribution
* Scripts de backup et maintenance
* Documentation API complète
? 🚀
oui je veux bien
PARTIE 9 : CONFIGURATION SUPABASE & DOCUMENTATION FINALE
9.1 Fichier scripts/setup_supabase.py
python
#!/usr/bin/env python3
"""
Script de configuration et migration vers Supabase
"""


import os
import sys
from supabase import create_client, Client
from dotenv import load_dotenv, set_key
import sqlalchemy
from sqlalchemy import create_engine, text
import json


load_dotenv()


class SupabaseSetup:
    def __init__(self):
        self.supabase_url = None
        self.supabase_key = None
        self.supabase_db_url = None
        self.client = None
    
    def collect_credentials(self):
        """Collecte les credentials Supabase"""
        print("🔐 Configuration Supabase")
        print("=" * 50)
        print("\n📝 Pour obtenir vos credentials Supabase:")
        print("1. Créez un projet sur https://supabase.com")
        print("2. Allez dans Settings > API")
        print("3. Copiez l'URL et les clés\n")
        
        self.supabase_url = input("Supabase URL (ex: https://xxxxx.supabase.co): ").strip()
        
        print("\n🔑 Vous avez besoin de 2 clés:")
        print("  - anon/public key (pour les requêtes frontend)")
        print("  - service_role key (pour les requêtes backend avec tous les droits)\n")
        
        self.supabase_anon_key = input("Supabase Anon Key: ").strip()
        self.supabase_service_key = input("Supabase Service Role Key: ").strip()
        
        print("\n🗄️  Pour la connexion PostgreSQL directe:")
        print("Allez dans Settings > Database > Connection string\n")
        
        self.supabase_db_url = input("Supabase Database URL (postgresql://...): ").strip()
    
    def validate_connection(self):
        """Valide la connexion à Supabase"""
        print("\n🔍 Validation de la connexion...")
        
        try:
            # Tester avec le client Supabase
            self.client = create_client(self.supabase_url, self.supabase_anon_key)
            
            # Tester une requête simple
            response = self.client.auth.get_session()
            
            print("✅ Connexion Supabase réussie")
            return True
            
        except Exception as e:
            print(f"❌ Erreur de connexion: {e}")
            return False
    
    def create_schema(self):
        """Crée le schéma de base de données sur Supabase"""
        print("\n📊 Création du schéma de base de données...")
        
        schema_sql = """
        -- Extension pour UUID
        CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
        
        -- Table des utilisateurs
        CREATE TABLE IF NOT EXISTS users (
            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
            username VARCHAR(255) UNIQUE NOT NULL,
            email VARCHAR(255) UNIQUE NOT NULL,
            hashed_password VARCHAR(255) NOT NULL,
            full_name VARCHAR(255),
            phone_number VARCHAR(20),
            is_active BOOLEAN DEFAULT TRUE,
            is_superuser BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- Table des conversations
        CREATE TABLE IF NOT EXISTS conversations (
            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
            user_id UUID REFERENCES users(id) ON DELETE CASCADE,
            source VARCHAR(50) DEFAULT 'web',
            status VARCHAR(50) DEFAULT 'active',
            mastodon_user VARCHAR(255),
            mastodon_post_id VARCHAR(255),
            context_token VARCHAR(255) UNIQUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- Table des messages
        CREATE TABLE IF NOT EXISTS messages (
            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
            conversation_id UUID REFERENCES conversations(id) ON DELETE CASCADE,
            role VARCHAR(50) NOT NULL,
            content TEXT NOT NULL,
            metadata JSONB,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- Table des tickets
        CREATE TABLE IF NOT EXISTS tickets (
            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
            conversation_id UUID REFERENCES conversations(id) ON DELETE CASCADE,
            priority VARCHAR(50) DEFAULT 'MEDIUM',
            status VARCHAR(50) DEFAULT 'OPEN',
            category VARCHAR(100),
            assigned_to UUID REFERENCES users(id),
            resolution_notes TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            resolved_at TIMESTAMP
        );
        
        -- Table des posts Mastodon
        CREATE TABLE IF NOT EXISTS mastodon_posts (
            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
            mastodon_id VARCHAR(255) UNIQUE NOT NULL,
            author_username VARCHAR(255) NOT NULL,
            content TEXT NOT NULL,
            is_complaint BOOLEAN DEFAULT FALSE,
            sentiment_score FLOAT,
            contact_link VARCHAR(500),
            conversation_id UUID REFERENCES conversations(id),
            replied BOOLEAN DEFAULT FALSE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- Table analytics
        CREATE TABLE IF NOT EXISTS analytics_events (
            id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
            event_type VARCHAR(100) NOT NULL,
            event_data JSONB,
            user_id UUID REFERENCES users(id),
            conversation_id UUID REFERENCES conversations(id),
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        
        -- Index
        CREATE INDEX IF NOT EXISTS idx_conversations_user ON conversations(user_id);
        CREATE INDEX IF NOT EXISTS idx_conversations_status ON conversations(status);
        CREATE INDEX IF NOT EXISTS idx_messages_conversation ON messages(conversation_id);
        CREATE INDEX IF NOT EXISTS idx_tickets_status ON tickets(status);
        CREATE INDEX IF NOT EXISTS idx_tickets_assigned ON tickets(assigned_to);
        CREATE INDEX IF NOT EXISTS idx_mastodon_posts_author ON mastodon_posts(author_username);
        CREATE INDEX IF NOT EXISTS idx_analytics_events_type ON analytics_events(event_type);
        CREATE INDEX IF NOT EXISTS idx_analytics_events_created ON analytics_events(created_at);
        
        -- Fonction de mise à jour timestamp
        CREATE OR REPLACE FUNCTION update_updated_at_column()
        RETURNS TRIGGER AS $$
        BEGIN
            NEW.updated_at = CURRENT_TIMESTAMP;
            RETURN NEW;
        END;
        $$ language 'plpgsql';
        
        -- Triggers
        DROP TRIGGER IF EXISTS update_users_updated_at ON users;
        CREATE TRIGGER update_users_updated_at BEFORE UPDATE ON users
            FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
        
        DROP TRIGGER IF EXISTS update_conversations_updated_at ON conversations;
        CREATE TRIGGER update_conversations_updated_at BEFORE UPDATE ON conversations
            FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
        
        DROP TRIGGER IF EXISTS update_tickets_updated_at ON tickets;
        CREATE TRIGGER update_tickets_updated_at BEFORE UPDATE ON tickets
            FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
        
        -- Row Level Security (RLS)
        ALTER TABLE users ENABLE ROW LEVEL SECURITY;
        ALTER TABLE conversations ENABLE ROW LEVEL SECURITY;
        ALTER TABLE messages ENABLE ROW LEVEL SECURITY;
        ALTER TABLE tickets ENABLE ROW LEVEL SECURITY;
        
        -- Policies (exemples basiques)
        CREATE POLICY "Users can view their own data" ON users
            FOR SELECT USING (auth.uid() = id);
        
        CREATE POLICY "Users can view their own conversations" ON conversations
            FOR SELECT USING (auth.uid() = user_id);
        
        CREATE POLICY "Users can view their own messages" ON messages
            FOR SELECT USING (
                conversation_id IN (
                    SELECT id FROM conversations WHERE user_id = auth.uid()
                )
            );
        """
        
        try:
            engine = create_engine(self.supabase_db_url)
            
            with engine.connect() as conn:
                # Exécuter chaque commande séparément
                for statement in schema_sql.split(';'):
                    if statement.strip():
                        conn.execute(text(statement))
                conn.commit()
            
            print("✅ Schéma créé avec succès")
            return True
            
        except Exception as e:
            print(f"❌ Erreur lors de la création du schéma: {e}")
            return False
    
    def migrate_from_local(self):
        """Migration des données depuis PostgreSQL local vers Supabase"""
        print("\n🔄 Migration des données locales vers Supabase...")
        
        response = input("Voulez-vous migrer les données depuis PostgreSQL local? (o/n): ")
        
        if response.lower() != 'o':
            print("⏭️  Migration ignorée")
            return
        
        try:
            # Connexion locale
            local_url = (
                f"postgresql://{os.getenv('POSTGRES_LOCAL_USER')}:"
                f"{os.getenv('POSTGRES_LOCAL_PASSWORD')}@"
                f"{os.getenv('POSTGRES_LOCAL_HOST')}:"
                f"{os.getenv('POSTGRES_LOCAL_PORT')}/"
                f"{os.getenv('POSTGRES_LOCAL_DB')}"
            )
            
            local_engine = create_engine(local_url)
            supabase_engine = create_engine(self.supabase_db_url)
            
            tables = ['users', 'conversations', 'messages', 'tickets', 'mastodon_posts', 'analytics_events']
            
            for table in tables:
                print(f"  📦 Migration de la table {table}...")
                
                # Lire depuis local
                with local_engine.connect() as conn:
                    result = conn.execute(text(f"SELECT * FROM {table}"))
                    rows = result.fetchall()
                    columns = result.keys()
                
                if not rows:
                    print(f"    ⏭️  Aucune donnée dans {table}")
                    continue
                
                # Insérer dans Supabase
                with supabase_engine.connect() as conn:
                    for row in rows:
                        placeholders = ', '.join([f':{col}' for col in columns])
                        insert_sql = f"INSERT INTO {table} ({', '.join(columns)}) VALUES ({placeholders})"
                        
                        row_dict = dict(zip(columns, row))
                        conn.execute(text(insert_sql), row_dict)
                    
                    conn.commit()
                
                print(f"    ✅ {len(rows)} enregistrements migrés")
            
            print("\n✅ Migration terminée avec succès")
            
        except Exception as e:
            print(f"❌ Erreur lors de la migration: {e}")
    
    def update_env_file(self):
        """Met à jour le fichier .env avec les credentials Supabase"""
        print("\n💾 Mise à jour du fichier .env...")
        
        env_file = '.env'
        
        set_key(env_file, 'USE_SUPABASE', 'true')
        set_key(env_file, 'SUPABASE_URL', self.supabase_url)
        set_key(env_file, 'SUPABASE_ANON_KEY', self.supabase_anon_key)
        set_key(env_file, 'SUPABASE_SERVICE_KEY', self.supabase_service_key)
        set_key(env_file, 'SUPABASE_DB_URL', self.supabase_db_url)
        
        print("✅ Fichier .env mis à jour")
    
    def setup_storage(self):
        """Configure le storage Supabase pour les fichiers"""
        print("\n📁 Configuration du Storage Supabase...")
        
        try:
            # Créer un bucket pour les fichiers
            buckets = ['documents', 'avatars', 'exports']
            
            for bucket_name in buckets:
                try:
                    self.client.storage.create_bucket(bucket_name, options={'public': False})
                    print(f"  ✅ Bucket '{bucket_name}' créé")
                except Exception as e:
                    if 'already exists' in str(e).lower():
                        print(f"  ⏭️  Bucket '{bucket_name}' existe déjà")
                    else:
                        print(f"  ⚠️  Erreur bucket '{bucket_name}': {e}")
            
        except Exception as e:
            print(f"❌ Erreur lors de la configuration du storage: {e}")
    
    def run(self):
        """Exécute la configuration complète"""
        print("\n" + "="*50)
        print("🚀 Configuration Supabase pour Free Mobile Chatbot")
        print("="*50 + "\n")
        
        # Étape 1: Collecter les credentials
        self.collect_credentials()
        
        # Étape 2: Valider la connexion
        if not self.validate_connection():
            print("\n❌ Configuration interrompue")
            return
        
        # Étape 3: Créer le schéma
        if not self.create_schema():
            print("\n❌ Configuration interrompue")
            return
        
        # Étape 4: Migration optionnelle
        self.migrate_from_local()
        
        # Étape 5: Configurer le storage
        self.setup_storage()
        
        # Étape 6: Mettre à jour .env
        self.update_env_file()
        
        print("\n" + "="*50)
        print("🎉 Configuration Supabase terminée!")
        print("="*50)
        
        print("\n📝 Prochaines étapes:")
        print("1. Vérifiez votre projet Supabase sur https://app.supabase.com")
        print("2. Configurez les politiques RLS selon vos besoins")
        print("3. Redémarrez l'application pour utiliser Supabase")
        print("\n💡 L'application utilisera maintenant Supabase au lieu de PostgreSQL local")


def main():
    setup = SupabaseSetup()
    setup.run()


if __name__ == "__main__":
    main()
9.2 Fichier scripts/backup_db.sh
bash
#!/bin/bash


# Script de backup de la base de données
# Usage: ./scripts/backup_db.sh [local|supabase]


set -e


source .env


BACKUP_DIR="./backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
ENVIRONMENT=${1:-local}


# Couleurs
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'


echo -e "${YELLOW}💾 Backup de la base de données - $ENVIRONMENT${NC}"


# Créer le dossier de backup
mkdir -p $BACKUP_DIR


case $ENVIRONMENT in
  local)
    BACKUP_FILE="$BACKUP_DIR/backup_local_$TIMESTAMP.sql"
    
    echo "📦 Backup PostgreSQL local..."
    
    PGPASSWORD=$POSTGRES_LOCAL_PASSWORD pg_dump \
      -h $POSTGRES_LOCAL_HOST \
      -p $POSTGRES_LOCAL_PORT \
      -U $POSTGRES_LOCAL_USER \
      -d $POSTGRES_LOCAL_DB \
      -F p \
      -f $BACKUP_FILE
    
    echo -e "${GREEN}✅ Backup créé: $BACKUP_FILE${NC}"
    
    # Compresser
    gzip $BACKUP_FILE
    echo -e "${GREEN}✅ Backup compressé: ${BACKUP_FILE}.gz${NC}"
    ;;
    
  supabase)
    BACKUP_FILE="$BACKUP_DIR/backup_supabase_$TIMESTAMP.sql"
    
    echo "📦 Backup Supabase..."
    
    # Extraire les informations de connexion depuis SUPABASE_DB_URL
    # Format: postgresql://user:pass@host:port/db
    
    if [ -z "$SUPABASE_DB_URL" ]; then
      echo -e "${RED}❌ SUPABASE_DB_URL non défini dans .env${NC}"
      exit 1
    fi
    
    pg_dump $SUPABASE_DB_URL -F p -f $BACKUP_FILE
    
    echo -e "${GREEN}✅ Backup créé: $BACKUP_FILE${NC}"
    
    # Compresser
    gzip $BACKUP_FILE
    echo -e "${GREEN}✅ Backup compressé: ${BACKUP_FILE}.gz${NC}"
    ;;
    
  *)
    echo -e "${RED}❌ Environnement invalide: $ENVIRONMENT${NC}"
    echo "Usage: ./scripts/backup_db.sh [local|supabase]"
    exit 1
    ;;
esac


# Nettoyer les vieux backups (garder seulement les 10 derniers)
echo "🧹 Nettoyage des anciens backups..."
ls -t $BACKUP_DIR/backup_*.sql.gz | tail -n +11 | xargs -r rm
echo -e "${GREEN}✅ Nettoyage terminé${NC}"


echo -e "\n${GREEN}✅ Backup terminé avec succès!${NC}"
echo "📁 Fichier: ${BACKUP_FILE}.gz"
echo "📊 Taille: $(du -h ${BACKUP_FILE}.gz | cut -f1)"
9.3 Fichier scripts/restore_db.sh
bash
#!/bin/bash


# Script de restauration de la base de données
# Usage: ./scripts/restore_db.sh [fichier_backup] [local|supabase]


set -e


source .env


BACKUP_FILE=$1
ENVIRONMENT=${2:-local}


# Couleurs
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
NC='\033[0m'


if [ -z "$BACKUP_FILE" ]; then
  echo -e "${RED}❌ Fichier de backup non spécifié${NC}"
  echo "Usage: ./scripts/restore_db.sh [fichier_backup] [local|supabase]"
  exit 1
fi


if [ ! -f "$BACKUP_FILE" ]; then
  echo -e "${RED}❌ Fichier introuvable: $BACKUP_FILE${NC}"
  exit 1
fi


echo -e "${YELLOW}⚠️  ATTENTION: Cette opération va ÉCRASER la base de données!${NC}"
read -p "Êtes-vous sûr de vouloir continuer? (oui/non): " confirmation


if [ "$confirmation" != "oui" ]; then
  echo "❌ Restauration annulée"
  exit 0
fi


# Décompresser si nécessaire
if [[ $BACKUP_FILE == *.gz ]]; then
  echo "📦 Décompression du backup..."
  gunzip -k $BACKUP_FILE
  BACKUP_FILE="${BACKUP_FILE%.gz}"
fi


case $ENVIRONMENT in
  local)
    echo "🔄 Restauration PostgreSQL local..."
    
    PGPASSWORD=$POSTGRES_LOCAL_PASSWORD psql \
      -h $POSTGRES_LOCAL_HOST \
      -p $POSTGRES_LOCAL_PORT \
      -U $POSTGRES_LOCAL_USER \
      -d $POSTGRES_LOCAL_DB \
      -f $BACKUP_FILE
    
    echo -e "${GREEN}✅ Restauration terminée${NC}"
    ;;
    
  supabase)
    echo "🔄 Restauration Supabase..."
    
    if [ -z "$SUPABASE_DB_URL" ]; then
      echo -e "${RED}❌ SUPABASE_DB_URL non défini dans .env${NC}"
      exit 1
    fi
    
    psql $SUPABASE_DB_URL -f $BACKUP_FILE
    
    echo -e "${GREEN}✅ Restauration terminée${NC}"
    ;;
    
  *)
    echo -e "${RED}❌ Environnement invalide: $ENVIRONMENT${NC}"
    exit 1
    ;;
esac


echo -e "\n${GREEN}🎉 Restauration réussie!${NC}"
9.4 Fichier README.md
markdown
# 🆓 Free Mobile - Chatbot SAV Intelligent


<div align="center">


![Free Mobile Logo](apps/frontend/static/images/logo.png)


**Plateforme complète de support client avec IA, RAG et intégration Mastodon**


[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)](https://streamlit.io/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)


</div>


---


## 📋 Table des Matières


- [Vue d'ensemble](#-vue-densemble)
- [Fonctionnalités](#-fonctionnalités)
- [Architecture](#-architecture)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Utilisation](#-utilisation)
- [Déploiement](#-déploiement)
- [API Documentation](#-api-documentation)
- [Contribution](#-contribution)
- [License](#-license)


---


## 🎯 Vue d'ensemble


Ce projet est une plateforme complète de support client pour Free Mobile, combinant :


- **Chatbot IA intelligent** avec système RAG (Retrieval-Augmented Generation)
- **Interface Streamlit** moderne et intuitive
- **Surveillance Mastodon** en temps réel pour détecter les réclamations
- **Système de ticketing** intégré avec escalade automatique
- **Analytics en temps réel** avec Plotly
- **Support multi-base de données** (PostgreSQL local + Supabase cloud)


### Technologies Utilisées
Frontend:        Streamlit 1.28+
Backend API:     FastAPI 0.104+
Base de données: PostgreSQL 15 / Supabase
Cache:           Redis 7
IA/LLM:          Transformers + Sentence-Transformers
Vector Store:    ChromaDB
Social:          Mastodon.py
Container:       Docker + Docker Compose


---


## ✨ Fonctionnalités


### 🤖 Chatbot Intelligent


- **RAG (Retrieval-Augmented Generation)** : Réponses basées sur la documentation Free Mobile
- **Détection d'intention** : Classification automatique des demandes
- **Analyse de sentiment** : Détection des réclamations et urgences
- **Escalade intelligente** : Transfert automatique vers agents humains si nécessaire
- **Multi-sources** : Support web, Mastodon, et autres canaux


### 🐘 Intégration Mastodon


- **Surveillance temps réel** des hashtags #Free, #FreeMobile, #SAVFree
- **Détection automatique** des réclamations sur les réseaux sociaux
- **Génération de liens** de contact uniques avec contexte préservé
- **Réponses automatiques** publiques avec redirection vers le chatbot
- **Création de tickets** automatique pour les cas urgents


### 📊 Analytics & Monitoring


- **Dashboard temps réel** avec KPIs clés
- **Graphiques interactifs** (conversations, tickets, satisfaction)
- **Analyse des intentions** et catégorisation
- **Métriques de performance** (temps de réponse, taux de résolution)
- **Rapports exportables** en CSV/PDF


### 🎫 Système de Ticketing


- **Création automatique** lors d'escalades
- **Priorisation intelligente** (LOW, MEDIUM, HIGH, URGENT)
- **Assignation** aux agents disponibles
- **Suivi complet** de l'état des tickets
- **Historique conservé** de toutes les interactions


---


## 🏗️ Architecture
┌─────────────────────────────────────────────────────────────┐
│                    UTILISATEURS                              │
│  (Web Browser, Mastodon, Mobile App)                        │
└────────────────┬────────────────────────────────────────────┘
│
▼
┌─────────────────────────────────────────────────────────────┐
│              FRONTEND (Streamlit)                            │
│  - Interface utilisateur                                     │
│  - Formulaire de contact                                     │
│  - Chat widget                                              │
│  - Dashboard analytics                                       │
└────────────────┬────────────────────────────────────────────┘
│
▼
┌─────────────────────────────────────────────────────────────┐
│              BACKEND API (FastAPI)                           │
│  - Gestion des conversations                                 │
│  - Gestion des tickets                                       │
│  - Authentification                                          │
│  - Analytics                                                 │
└───────┬──────────────┬──────────────┬───────────────────────┘
│              │              │
▼              ▼              ▼
┌──────────────┐ ┌──────────┐ ┌────────────────┐
│  PostgreSQL  │ │  Redis   │ │  AI Engine     │
│  / Supabase  │ │  Cache   │ │  (RAG + LLM)   │
└──────────────┘ └──────────┘ └────────┬───────┘
│
▼
┌───────────────┐
│   ChromaDB    │
│ Vector Store  │
└───────────────┘
┌─────────────────────────────────────────────────────────────┐
│           SOCIAL MONITOR (Mastodon)                          │
│  - Surveillance hashtags                                     │
│  - Détection réclamations                                    │
│  - Génération liens                                          │
│  - Réponses automatiques                                     │
└─────────────────────────────────────────────────────────────┘


### Structure des Dossiers
chatbot-free-mobile/
├── apps/
│   ├── frontend/          # Application Streamlit
│   ├── backend/           # API FastAPI
│   ├── ai-engine/         # Moteur IA + RAG
│   └── social-monitor/    # Surveillance Mastodon
├── data/
│   ├── raw/               # Données brutes (FAQs, docs)
│   ├── processed/         # Datasets préparés
│   ├── vector_store/      # Base vectorielle ChromaDB
│   └── scripts/           # Scripts de traitement
├── infrastructure/
│   └── docker/            # Configuration Docker
├── scripts/               # Scripts utilitaires
├── tests/                 # Tests unitaires et intégration
└── docs/                  # Documentation


---


## 🚀 Installation


### Prérequis


- **Python 3.10+**
- **Docker & Docker Compose**
- **Git**
- **PostgreSQL 15** (optionnel si vous utilisez Docker)
- **Redis** (optionnel si vous utilisez Docker)


### Installation Rapide
```bash
# 1. Cloner le repository
git clone https://github.com/votre-username/chatbot-free-mobile.git
cd chatbot-free-mobile


# 2. Exécuter le script de configuration
chmod +x scripts/setup_dev.sh
./scripts/setup_dev.sh


# 3. Copier et configurer .env
cp .env.example .env
# Éditez .env avec vos paramètres


# 4. Initialiser la base de données
python scripts/init_database.py local


# 5. Préparer les datasets
python data/scripts/prepare_dataset.py


# 6. Charger les données dans ChromaDB
python data/scripts/load_to_vectorstore.py


# 7. Lancer l'application avec Docker
docker-compose -f infrastructure/docker/docker-compose.yml up -d
Installation Manuelle (sans Docker)
bash
# 1. Créer un environnement virtuel
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows


# 2. Installer les dépendances
pip install -r requirements.txt


# 3. Installer PostgreSQL et Redis localement
# (voir documentation de votre système d'exploitation)


# 4. Configurer .env
cp .env.example .env
# Éditer .env


# 5. Initialiser la base de données
python scripts/init_database.py local


# 6. Préparer les données
python data/scripts/prepare_dataset.py
python data/scripts/load_to_vectorstore.py


# 7. Lancer les services
# Terminal 1 - Backend
cd apps/backend
uvicorn main:app --reload --port 8000


# Terminal 2 - AI Engine
cd apps/ai-engine
python api.py


# Terminal 3 - Social Monitor
cd apps/social-monitor
python main.py


# Terminal 4 - Frontend
cd apps/frontend
streamlit run app.py
________________


⚙️ Configuration
1. Configuration Mastodon
bash
python scripts/setup_mastodon.py
Suivez les instructions pour :
* Créer une application Mastodon
* Obtenir les tokens d'accès
* Configurer les hashtags à surveiller
2. Configuration Supabase (optionnel)
bash
python scripts/setup_supabase.py
Pour utiliser Supabase au lieu de PostgreSQL local :
* Créez un projet sur https://supabase.com
* Récupérez vos credentials
* Exécutez le script de configuration
3. Variables d'Environnement
Les variables principales dans .env :
bash
# Base de données
USE_SUPABASE=false  # true pour Supabase, false pour local
POSTGRES_LOCAL_HOST=localhost
POSTGRES_LOCAL_USER=chatbot_user
POSTGRES_LOCAL_PASSWORD=your_password
POSTGRES_LOCAL_DB=chatbot_free_mobile


# Mastodon
MASTODON_INSTANCE_URL=https://mastodon.social
MASTODON_ACCESS_TOKEN=your_token
MASTODON_MONITOR_HASHTAGS=Free,FreeMobile,SAVFree


# IA
LLM_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
Continuer
Security
SECRET_KEY=your-secret-key-change-in-production-min-32-chars


### 4. Ajout de Données d'Entraînement


Ajoutez vos propres FAQs dans `data/raw/faqs/` :
```json
{
  "question": "Votre question ici",
  "answer": "La réponse détaillée",
  "category": "facturation|technique|forfait|resiliation",
  "tags": ["tag1", "tag2"]
}
Puis rechargez :
bash
python data/scripts/prepare_dataset.py
python data/scripts/load_to_vectorstore.py
________________


📖 Utilisation
Accès aux Interfaces
Une fois l'application lancée :
Service
	URL
	Description
	Frontend
	http://localhost:8501
	Interface utilisateur principale
	Backend API
	http://localhost:8000
	API REST (documentation auto)
	API Docs
	http://localhost:8000/docs
	Documentation Swagger interactive
	AI Engine
	http://localhost:8001
	Moteur IA (endpoints internes)
	PgAdmin
	http://localhost:5050
	Administration PostgreSQL
	Redis
	localhost:6379
	Cache (accès direct)
	Comptes par Défaut
PgAdmin :
* Email: admin@freemobile.local
* Mot de passe: admin123
Admin Application :
* Username: admin
* Mot de passe: admin123
⚠️ Changez ces mots de passe en production !
Utilisation du Chatbot
1. Accédez à http://localhost:8501
2. Remplissez le formulaire de contact avec vos informations
3. Commencez à chatter avec l'assistant virtuel
4. Le chatbot répondra automatiquement en utilisant la base de connaissances
5. Si nécessaire, votre conversation sera transférée à un agent humain
Utilisation de Mastodon
1. Postez sur Mastodon avec le hashtag #Free ou #FreeMobile
2. Le bot détecte automatiquement votre message
3. Il analyse s'il s'agit d'une réclamation
4. Il répond publiquement avec un lien vers le chatbot
5. Cliquez sur le lien pour continuer en privé avec le contexte préservé
Gestion des Tickets
1. Accédez à "Mes Tickets" dans l'interface
2. Visualisez tous vos tickets ouverts/fermés
3. Filtrez par statut, priorité, catégorie
4. Consultez l'historique complet de chaque ticket
Consultation des Analytics
1. Accédez à "Analytics" dans le menu
2. Sélectionnez une période
3. Visualisez :
   * Nombre de conversations
   * Taux de résolution
   * Distribution des intentions
   * Performance du chatbot
   * Satisfaction client
________________


🚀 Déploiement
Déploiement Local avec Docker
bash
# Démarrer tous les services
./scripts/deploy.sh local


# Voir les logs
docker-compose -f infrastructure/docker/docker-compose.yml logs -f


# Arrêter les services
docker-compose -f infrastructure/docker/docker-compose.yml down


# Arrêter et supprimer les volumes
docker-compose -f infrastructure/docker/docker-compose.yml down -v
Déploiement sur Serveur VPS
bash
# 1. Installer Docker sur le serveur
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh


# 2. Installer Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose


# 3. Cloner le projet
git clone https://github.com/votre-username/chatbot-free-mobile.git
cd chatbot-free-mobile


# 4. Configurer .env pour production
cp .env.example .env
nano .env  # Modifier avec vos paramètres de production


# 5. Lancer en mode production
docker-compose -f infrastructure/docker/docker-compose.yml up -d


# 6. Configurer un reverse proxy (nginx)
sudo apt install nginx
# Configurer nginx pour rediriger vers les ports Docker
Configuration Nginx (exemple)
nginx
# /etc/nginx/sites-available/chatbot-freemobile


server {
    listen 80;
    server_name votre-domaine.com;


    # Frontend Streamlit
    location / {
        proxy_pass http://localhost:8501;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }


    # Backend API
    location /api {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
Déploiement avec Supabase
bash
# 1. Créer un projet Supabase
# Sur https://supabase.com


# 2. Configurer Supabase
python scripts/setup_supabase.py


# 3. Modifier .env
USE_SUPABASE=true


# 4. Redémarrer les services
docker-compose -f infrastructure/docker/docker-compose.yml restart
CI/CD avec GitHub Actions
Le projet inclut des workflows GitHub Actions :
* .github/workflows/ci.yml : Tests automatiques
* .github/workflows/deploy-production.yml : Déploiement auto
Pour activer :
1. Ajoutez les secrets dans GitHub :
   * DOCKER_USERNAME
   * DOCKER_PASSWORD
   * PRODUCTION_HOST
   * PRODUCTION_USER
   * SSH_PRIVATE_KEY
2. Poussez sur main pour déclencher le déploiement
________________


📚 API Documentation
Backend API (FastAPI)
Documentation interactive disponible à : http://localhost:8000/docs
Principaux Endpoints
Chat
http
POST /api/v1/chat/message
Content-Type: application/json


{
  "message": "Comment consulter ma facture ?",
  "conversation_id": "uuid-optional",
  "context_token": "token-from-mastodon-optional",
  "user_info": {
    "full_name": "Jean Dupont",
    "phone_number": "0612345678",
    "email": "jean@example.com"
  }
}
Réponse :
json
{
  "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
  "message": {
    "id": "...",
    "role": "user",
    "content": "Comment consulter ma facture ?",
    "created_at": "2024-01-15T10:30:00Z"
  },
  "response": {
    "id": "...",
    "role": "assistant",
    "content": "Vous pouvez consulter votre facture...",
    "created_at": "2024-01-15T10:30:02Z"
  },
  "needs_escalation": false,
  "suggested_links": [
    {
      "title": "FAQ Free Mobile",
      "url": "https://mobile.free.fr/assistance/",
      "description": "Consultez notre aide en ligne"
    }
  ]
}
Tickets
http
GET /api/v1/tickets?status=OPEN
Authorization: Bearer {token}
Analytics
http
GET /api/v1/analytics?start_date=2024-01-01&end_date=2024-01-31
Authorization: Bearer {token}
AI Engine API
Générer une réponse
http
POST /api/generate
Content-Type: application/json


{
  "message": "Problème de réseau",
  "conversation_history": [
    {"role": "user", "content": "Bonjour"},
    {"role": "assistant", "content": "Bonjour, comment puis-je vous aider ?"}
  ]
}
Réponse :
json
{
  "response": "Je comprends votre problème de réseau...",
  "needs_escalation": false,
  "category": "technique",
  "confidence": 0.92,
  "sources": [
    {
      "type": "faq",
      "category": "technique",
      "source": "technique.json"
    }
  ]
}
Ingérer des documents
http
POST /api/ingest-documents
Statistiques
http
GET /api/stats
________________


🧪 Tests
Exécuter les Tests
bash
# Tous les tests
pytest


# Tests avec couverture
pytest --cov=apps --cov-report=html


# Tests unitaires seulement
pytest tests/unit/


# Tests d'intégration
pytest tests/integration/


# Tests spécifiques
pytest tests/unit/test_backend/test_chat_service.py
Structure des Tests
tests/
├── unit/
│   ├── test_backend/
│   │   ├── test_chat_service.py
│   │   ├── test_ticket_service.py
│   │   └── test_analytics_service.py
│   ├── test_ai_engine/
│   │   ├── test_response_generator.py
│   │   ├── test_vector_store.py
│   │   └── test_intent_detector.py
│   └── test_social_monitor/
│       ├── test_complaint_detector.py
│       └── test_link_generator.py
├── integration/
│   ├── test_chat_flow.py
│   ├── test_mastodon_integration.py
│   └── test_escalation_flow.py
└── fixtures/
    └── sample_data.json
Exemple de Test
python
# tests/unit/test_backend/test_chat_service.py
import pytest
from apps.backend.services.chat_service import ChatService


@pytest.fixture
def chat_service(db_session):
    return ChatService(db_session)


def test_create_conversation(chat_service):
    conversation = await chat_service.get_or_create_conversation(
        source="web"
    )
    assert conversation.id is not None
    assert conversation.source == "web"
    assert conversation.status == "active"


def test_save_message(chat_service, conversation):
    message = await chat_service.save_message(
        conversation_id=conversation.id,
        role="user",
        content="Test message"
    )
    assert message.content == "Test message"
    assert message.role == "user"
________________


🛠️ Maintenance
Backup de la Base de Données
bash
# Backup PostgreSQL local
./scripts/backup_db.sh local


# Backup Supabase
./scripts/backup_db.sh supabase


# Les backups sont sauvegardés dans ./backups/
Restauration
bash
# Restaurer depuis un backup
./scripts/restore_db.sh backups/backup_local_20240115_103000.sql.gz local
Mise à Jour des Dépendances
bash
# Mettre à jour requirements.txt
pip list --outdated
pip install --upgrade package_name


# Régénérer requirements.txt
pip freeze > requirements.txt


# Rebuild les images Docker
docker-compose -f infrastructure/docker/docker-compose.yml build
Monitoring des Services
bash
# Statut des containers
docker-compose -f infrastructure/docker/docker-compose.yml ps


# Logs en temps réel
docker-compose -f infrastructure/docker/docker-compose.yml logs -f


# Logs d'un service spécifique
docker-compose -f infrastructure/docker/docker-compose.yml logs -f backend


# Utilisation des ressources
docker stats


# Vérifier la santé des services
curl http://localhost:8000/health
curl http://localhost:8001/
Nettoyage
bash
# Supprimer les containers arrêtés
docker container prune


# Supprimer les images non utilisées
docker image prune


# Supprimer les volumes non utilisés
docker volume prune


# Nettoyage complet (ATTENTION : supprime tout)
docker system prune -a --volumes
________________


📊 Performance & Optimisation
Optimisations Backend
1. Cache Redis : Mise en cache des réponses fréquentes
2. Connection Pooling : Pool de connexions PostgreSQL
3. Async/Await : Opérations asynchrones pour meilleure performance
4. Pagination : Limitation des résultats API
Optimisations AI Engine
1. Batch Processing : Traitement par lots des embeddings
2. Model Caching : Chargement unique du modèle en mémoire
3. GPU Support : Support CUDA pour accélération (optionnel)
4. Vector Store Indexing : Index optimisé pour recherche rapide
Recommandations Production
bash
# Ressources recommandées
CPU: 4+ cores
RAM: 16+ GB (32 GB recommandé avec modèles LLM)
Stockage: 50+ GB SSD
GPU: NVIDIA avec 8+ GB VRAM (optionnel mais recommandé)


# Variables d'environnement production
DEBUG=false
LOG_LEVEL=INFO
WORKERS=4  # Pour uvicorn
________________


🐛 Dépannage
Problèmes Courants
1. Le chatbot ne répond pas
bash
# Vérifier que l'AI Engine est démarré
curl http://localhost:8001/


# Vérifier les logs
docker-compose logs ai-engine


# Recharger le vector store
python data/scripts/load_to_vectorstore.py
2. Erreur de connexion à la base de données
bash
# Vérifier que PostgreSQL est démarré
docker-compose ps postgres


# Tester la connexion
psql -h localhost -U chatbot_user -d chatbot_free_mobile


# Vérifier les variables .env
cat .env | grep POSTGRES
3. Mastodon ne détecte pas les posts
bash
# Vérifier les credentials
python scripts/setup_mastodon.py


# Vérifier que le service tourne
docker-compose ps social-monitor


# Voir les logs
docker-compose logs social-monitor
4. Erreur de mémoire avec le modèle LLM
bash
# Utiliser un modèle plus léger
# Dans .env :
LLM_MODEL_NAME=gpt2  # Plus léger que Mistral


# Ou augmenter la RAM Docker
# Dans Docker Desktop: Settings > Resources > Memory
5. ChromaDB vide ou introuvable
bash
# Recharger les documents
python data/scripts/load_to_vectorstore.py


# Vérifier le path
ls -la data/vector_store/


# Recréer la base vectorielle
# Dans le script, répondre 'o' pour réinitialiser
Logs et Debugging
bash
# Activer le mode debug
# Dans .env :
DEBUG=true
LOG_LEVEL=DEBUG


# Consulter les logs détaillés
docker-compose logs -f --tail=100


# Logs spécifiques par service
docker-compose logs -f backend
docker-compose logs -f ai-engine
docker-compose logs -f social-monitor
________________


🤝 Contribution
Nous accueillons les contributions ! Voici comment participer :
Processus de Contribution
1. Fork le projet
2. Créez une branche pour votre fonctionnalité (git checkout -b feature/AmazingFeature)
3. Committez vos changements (git commit -m 'Add some AmazingFeature')
4. Poussez vers la branche (git push origin feature/AmazingFeature)
5. Ouvrez une Pull Request
Standards de Code
python
# Suivre PEP 8 pour Python
black apps/  # Formatter le code
flake8 apps/  # Vérifier le style
mypy apps/  # Vérifier les types


# Ajouter des tests
pytest tests/


# Documenter les fonctions
def ma_fonction(param: str) -> dict:
    """
    Description de la fonction.
    
    Args:
        param: Description du paramètre
        
    Returns:
        Description du retour
    """
    pass
Checklist Pull Request
*  Le code suit les standards du projet
*  Les tests passent (pytest)
*  Les nouveaux tests sont ajoutés si nécessaire
*  La documentation est mise à jour
*  Le CHANGELOG.md est mis à jour
*  Les commits sont clairs et descriptifs
Rapporter un Bug
Créez une issue avec :
1. Description : Description claire et concise du bug
2. Reproduction : Étapes pour reproduire le comportement
3. Attendu : Comportement attendu
4. Screenshots : Si applicable
5. Environnement : OS, version Python, Docker, etc.
Proposer une Fonctionnalité
Créez une issue avec :
1. Problème : Quel problème cette fonctionnalité résout-elle ?
2. Solution : Description de la solution proposée
3. Alternatives : Alternatives considérées
4. Contexte : Contexte additionnel
________________


📄 License
Ce projet est sous licence MIT. Voir le fichier LICENSE pour plus de détails.
MIT License


Copyright (c) 2024 Free Mobile Chatbot


Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:


The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.


THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
________________


👥 Équipe
* Développeur Principal : Votre Nom
* Contributeurs : Voir CONTRIBUTORS.md
________________


📞 Support
* Documentation : docs/
* Issues : GitHub Issues
* Email : support@votre-domaine.com
________________


🎉 Remerciements
* Streamlit pour le framework frontend
* FastAPI pour le framework backend
* Hugging Face pour les modèles de NLP
* ChromaDB pour le vector store
* Mastodon pour l'API sociale
* Supabase pour l'infrastructure cloud
________________


🗺️ Roadmap
Version 1.1 (Q2 2024)
*  Support multilingue (Anglais, Espagnol)
*  Application mobile (React Native)
*  Intégration Twitter/X
*  Système de notifications push
Version 1.2 (Q3 2024)
*  Fine-tuning du modèle LLM
*  Dashboard admin avancé
*  API publique avec rate limiting
*  Webhooks pour intégrations tierces
Version 2.0 (Q4 2024)
*  Support vocal (Speech-to-Text)
*  Vidéo chat avec agents
*  IA prédictive pour anticiper les problèmes
*  Marketplace de plugins
________________
<div align="center">
Fait avec ❤️ pour Free Mobile
Documentation · Report Bug · Request Feature
</div> ```
9.5 Fichier CONTRIBUTING.md
markdown
# Guide de Contribution


Merci de votre intérêt pour contribuer au projet Free Mobile Chatbot ! Ce document vous guidera à travers le processus de contribution.


## 📋 Table des Matières


- [Code de Conduite](#code-de-conduite)
- [Comment Contribuer](#comment-contribuer)
- [Standards de Code](#standards-de-code)
- [Processus de Pull Request](#processus-de-pull-request)
- [Rapporter des Bugs](#rapporter-des-bugs)
- [Proposer des Fonctionnalités](#proposer-des-fonctionnalités)


## Code de Conduite


### Notre Engagement


Nous nous engageons à faire de la participation à notre projet une expérience sans harcèlement pour tous, indépendamment de l'âge, de la taille, du handicap, de l'ethnicité, de l'identité et de l'expression de genre, du niveau d'expérience, de la nationalité, de l'apparence personnelle, de la race, de la religion ou de l'identité et de l'orientation sexuelles.


### Nos Standards


Exemples de comportements qui contribuent à créer un environnement positif :


- Utiliser un langage accueillant et inclusif
- Respecter les différents points de vue et expériences
- Accepter gracieusement les critiques constructives
- Se concentrer sur ce qui est le mieux pour la communauté
- Faire preuve d'empathie envers les autres membres de la communauté


## Comment Contribuer


### 1. Configuration de l'Environnement
```bash
# Fork le projet sur GitHub
# Clone votre fork
git clone https://github.com/VOTRE-USERNAME/chatbot-free-mobile.git
cd chatbot-free-mobile


# Ajouter le repo original comme remote
git remote add upstream https://github.com/ORIGINAL-USERNAME/chatbot-free-mobile.git


# Installer les dépendances
./scripts/setup_dev.sh
2. Créer une Branche
bash
# Mettre à jour main
git checkout main
git pull upstream main


# Créer une branche pour votre feature
git checkout -b feature/ma-super-feature


# Ou pour un bugfix
git checkout -b fix/correction-bug
3. Faire vos Modifications
* Suivez les Standards de Code
* Ajoutez des tests pour les nouvelles fonctionnalités
* Mettez à jour la documentation si nécessaire
* Committez régulièrement avec des messages clairs
bash
git add .
git commit -m "feat: ajoute une nouvelle fonctionnalité géniale"
4. Pousser et Créer une Pull Request
bash
git push origin feature/ma-super-feature
Puis créez une Pull Request sur GitHub.
Standards de Code
Python
python
# Suivre PEP 8
# Utiliser Black pour le formatting
black apps/


# Utiliser flake8 pour le linting
flake8 apps/ --max-line-length=100


# Utiliser mypy pour le type checking
mypy apps/
Conventions de Nommage
python
# Variables et fonctions: snake_case
ma_variable = "valeur"
def ma_fonction():
    pass


# Classes: PascalCase
class MaClasse:
    pass


# Constantes: UPPER_SNAKE_CASE
MA_CONSTANTE = 42


# Privé: préfixe underscore
def _fonction_privee():
    pass
Documentation
python
def ma_fonction(param1: str, param2: int) -> dict:
    """
    Description courte de la fonction.
    
    Description longue optionnelle avec plus de détails
    sur ce que fait la fonction.
    
    Args:
        param1: Description du premier paramètre
        param2: Description du deuxième paramètre
        
    Returns:
        Description de ce qui est retourné
        
    Raises:
        ValueError: Quand param2 est négatif
        
    Example:
        >>> ma_fonction("test", 5)
        {'result': 'test5'}
    """
    if param2 < 0:
        raise ValueError("param2 doit être positif")
    
    return {'result': param1 + str(param2)}
Tests
python
import pytest


def test_ma_fonction():
    """Test de ma_fonction avec des valeurs valides"""
    result = ma_fonction("test", 5)
    assert result == {'result': 'test5'}


def test_ma_fonction_erreur():
    """Test que ma_fonction raise une ValueError"""
    with pytest.raises(ValueError):
        ma_fonction("test", -1)
Processus de Pull Request
Checklist PR
Avant de soumettre une PR, assurez-vous que :
*  Le code suit les standards du projet
*  Tous les tests passent (pytest)
*  Les nouveaux tests sont ajoutés
*  La couverture de code n'a pas diminué
*  La documentation est mise à jour
*  Le CHANGELOG.md est mis à jour
*  Les commits suivent la convention (voir ci-dessous)
Convention de Commits
Nous suivons la Conventional Commits :
type(scope): description courte


[corps optionnel]


[footer optionnel]
Types:
* feat: Nouvelle fonctionnalité
* fix: Correction de bug
* docs: Documentation uniquement
* style: Changements qui n'affectent pas le sens du code
* refactor: Changement de code qui ne corrige pas un bug ni n'ajoute une fonctionnalité
* perf: Amélioration des performances
* test: Ajout de tests manquants
* chore: Changements aux outils de build ou dépendances
Exemples:
feat(chatbot): ajoute support multilingue
fix(api): corrige l'erreur 500 lors de la création de ticket
docs(readme): met à jour les instructions d'installation
Template de Pull Request
markdown
## Description
Description claire de ce que fait cette PR


## Type de changement
- [ ] Bug fix
- [ ] Nouvelle fonctionnalité
- [ ] Breaking change
- [ ] Documentation


## Comment a-t-il été testé?
Décrivez les tests effectués


## Checklist
- [ ] Mon code suit les standards du projet
- [ ] J'ai effectué une auto-revue de mon code
- [ ] J'ai commenté mon code, en particulier les parties difficiles
- [ ] J'ai mis à jour la documentation
- [ ] Mes changements ne génèrent pas de nouveaux warnings
- [ ] J'ai ajouté des tests qui prouvent que mon fix est efficace
- [ ] Les tests unitaires passent localement
Rapporter des Bugs
Template de Bug Report
markdown
**Describe the bug**
Une description claire et concise du bug.


**To Reproduce**
Steps pour reproduire le comportement:
1. Aller à '...'
2. Cliquer sur '....'
3. Scroller jusqu'à '....'
4. Voir l'erreur


**Expected behavior**
Une description claire de ce qui devrait se passer.


**Screenshots**
Si applicable, ajoutez des screenshots.


**Environment:**
 - OS: [e.g. Ubuntu 22.04]
 - Python Version: [e.g. 3.10.5]
 - Docker Version: [e.g. 20.10.17]
 - Browser: [e.g. chrome, safari]


**Additional context**
Tout autre contexte utile.
Proposer des Fonctionnalités
Template de Feature Request
markdown
**Is your feature request related to a problem?**
Une description claire du problème. Ex: Je suis frustré quand [...]


**Describe the solution you'd like**
Une description claire de ce que vous voulez qu'il se passe.


**Describe alternatives you've considered**
Une description claire des solutions ou fonctionnalités alternatives.


**Additional context**
Tout autre contexte ou screenshots.
Domaines de Contribution
Nous accueillons les contributions dans les domaines suivants :
🐛 Corrections de Bugs
* Correction de bugs existants
* Amélioration de la gestion d'erreurs
* Optimisation des performances
✨ Nouvelles Fonctionnalités
* Nouvelles capacités du chatbot
* Intégrations avec d'autres services
* Améliorations UI/UX
📚 Documentation
* Amélioration de la documentation
* Traductions
* Tutoriels et guides
🧪 Tests
* Ajout de tests unitaires
* Tests d'intégration
* Tests de performance
🎨 Design
* Améliorations UI
* Accessibilité
* Responsive design
Questions?
N'hésitez pas à :
* Ouvrir une Discussion
* Créer une Issue
* Contacter les mainteneurs
________________


Merci pour vos contributions ! 🎉


## 9.6 Fichier CHANGELOG.md
```markdown
# Changelog


Tous les changements notables de ce projet seront documentés dans ce fichier.


Le format est basé sur [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
et ce projet adhère à [Semantic Versioning](https://semver.org/spec/v2.0.0.html).


## [Unreleased]


### Added
- Support pour GPU CUDA dans l'AI Engine
- Export des analytics en PDF
- Notifications email pour les tickets urgents


### Changed
- Amélioration des performances du vector store
- Mise à jour de Streamlit vers 1.29


### Fixed
- Correction du bug de timeout lors de requêtes longues
- Fix de l'encodage UTF-8 pour les accents


## [1.0.0] - 2024-01-15


### Added
- 🎉 Version initiale du chatbot
- Interface Streamlit complète
- API Fast
Continuer
API FastAPI avec endpoints REST
* Moteur IA avec RAG (ChromaDB + Transformers)
* Intégration Mastodon pour surveillance sociale
* Système de ticketing automatique
* Dashboard analytics avec Plotly
* Support PostgreSQL local et Supabase
* Cache Redis pour optimisation
* Docker Compose pour déploiement
* Documentation complète
* Tests unitaires et d'intégration
* Scripts de setup et déploiement
* Backup et restauration automatiques
Features Principales
Chatbot Intelligent
* Réponses basées sur RAG avec ChromaDB
* Détection d'intention automatique
* Analyse de sentiment
* Escalade intelligente vers agents humains
* Support multi-sources (web, Mastodon)
Surveillance Mastodon
* Monitoring temps réel des hashtags
* Détection automatique des réclamations
* Génération de liens personnalisés
* Réponses automatiques publiques
* Préservation du contexte
Analytics
* KPIs en temps réel
* Graphiques interactifs (Plotly)
* Distribution des intentions
* Performance du chatbot
* Satisfaction client
Système de Ticketing
* Création automatique lors d'escalades
* Priorisation intelligente (LOW, MEDIUM, HIGH, URGENT)
* Assignation aux agents
* Suivi complet de l'état
* Historique conservé
Technical Stack
* Python 3.10+
* Streamlit 1.28+
* FastAPI 0.104+
* PostgreSQL 15 / Supabase
* Redis 7
* ChromaDB 0.4+
* Transformers 4.35+
* Mastodon.py 1.8+
* Docker & Docker Compose
0.9.0 - 2024-01-10 (Beta)
Added
* Prototype du chatbot avec réponses pré-définies
* Interface Streamlit basique
* Connexion PostgreSQL
* FAQs initiales
Changed
* Migration de Node.js vers FastAPI pour cohérence
Removed
* Backend Node.js initial
0.5.0 - 2024-01-05 (Alpha)
Added
* Structure initiale du projet
* Configuration Docker
* Base de données PostgreSQL
* Scripts de setup
________________


Types de Changements
* Added : Nouvelles fonctionnalités
* Changed : Changements dans les fonctionnalités existantes
* Deprecated : Fonctionnalités bientôt supprimées
* Removed : Fonctionnalités supprimées
* Fixed : Corrections de bugs
* Security : Corrections de vulnérabilités


## 9.7 Fichier docs/API.md
```markdown
# Documentation API - Free Mobile Chatbot


## Vue d'ensemble


L'API du chatbot Free Mobile est construite avec FastAPI et fournit des endpoints RESTful pour :
- Gestion des conversations
- Traitement des messages
- Gestion des tickets
- Analytics et statistiques
- Intégration Mastodon


**Base URL:** `http://localhost:8000/api/v1`


**Documentation interactive:** `http://localhost:8000/docs`


## Authentication


L'API utilise JWT (JSON Web Tokens) pour l'authentification.


### Obtenir un Token
```http
POST /auth/login
Content-Type: application/json


{
  "username": "user@example.com",
  "password": "your_password"
}
Réponse:
json
{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...",
  "token_type": "bearer",
  "expires_in": 1800
}
Utiliser le Token
Incluez le token dans le header de toutes les requêtes authentifiées :
http
Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
Endpoints
Chat
Envoyer un Message
Envoie un message au chatbot et obtient une réponse.
http
POST /chat/message
Content-Type: application/json


{
  "message": "Comment consulter ma facture ?",
  "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
  "context_token": "abc123def456",
  "user_info": {
    "full_name": "Jean Dupont",
    "phone_number": "0612345678",
    "email": "jean@example.com"
  }
}
Paramètres:
* message (string, requis) : Le message de l'utilisateur
* conversation_id (uuid, optionnel) : ID d'une conversation existante
* context_token (string, optionnel) : Token de contexte (depuis Mastodon)
* user_info (object, optionnel) : Informations de l'utilisateur
Réponse:
json
{
  "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
  "message": {
    "id": "660e8400-e29b-41d4-a716-446655440000",
    "role": "user",
    "content": "Comment consulter ma facture ?",
    "created_at": "2024-01-15T10:30:00Z"
  },
  "response": {
    "id": "770e8400-e29b-41d4-a716-446655440000",
    "role": "assistant",
    "content": "Vous pouvez consulter votre facture de plusieurs façons...",
    "created_at": "2024-01-15T10:30:02Z"
  },
  "needs_escalation": false,
  "suggested_links": [
    {
      "title": "FAQ Free Mobile",
      "url": "https://mobile.free.fr/assistance/",
      "description": "Consultez notre aide en ligne"
    }
  ]
}
Codes d'état:
* 200 OK : Message traité avec succès
* 400 Bad Request : Paramètres invalides
* 500 Internal Server Error : Erreur serveur
________________


Récupérer l'Historique de Conversation
http
GET /chat/conversation/{conversation_id}/messages
Authorization: Bearer {token}
Paramètres de requête:
* limit (int, optionnel, défaut=50) : Nombre maximum de messages
* offset (int, optionnel, défaut=0) : Décalage pour pagination
Réponse:
json
[
  {
    "id": "660e8400-e29b-41d4-a716-446655440000",
    "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
    "role": "user",
    "content": "Bonjour",
    "created_at": "2024-01-15T10:25:00Z"
  },
  {
    "id": "770e8400-e29b-41d4-a716-446655440000",
    "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
    "role": "assistant",
    "content": "Bonjour ! Comment puis-je vous aider ?",
    "created_at": "2024-01-15T10:25:01Z"
  }
]
________________


Lister les Conversations
http
GET /chat/conversations
Authorization: Bearer {token}
Paramètres de requête:
* status (string, optionnel) : Filtrer par statut (active, closed, escalated)
* source (string, optionnel) : Filtrer par source (web, mastodon)
* limit (int, optionnel, défaut=20)
* offset (int, optionnel, défaut=0)
Réponse:
json
{
  "total": 45,
  "items": [
    {
      "id": "550e8400-e29b-41d4-a716-446655440000",
      "user_id": "440e8400-e29b-41d4-a716-446655440000",
      "source": "web",
      "status": "active",
      "created_at": "2024-01-15T10:25:00Z",
      "updated_at": "2024-01-15T10:30:00Z",
      "message_count": 8
    }
  ]
}
________________


Tickets
Créer un Ticket
http
POST /tickets
Authorization: Bearer {token}
Content-Type: application/json


{
  "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
  "priority": "HIGH",
  "category": "technique",
  "description": "Problème de réseau persistant"
}
Paramètres:
* conversation_id (uuid, requis)
* priority (string, requis) : LOW, MEDIUM, HIGH, URGENT
* category (string, requis)
* description (string, optionnel)
Réponse:
json
{
  "id": "880e8400-e29b-41d4-a716-446655440000",
  "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
  "priority": "HIGH",
  "status": "OPEN",
  "category": "technique",
  "created_at": "2024-01-15T10:35:00Z"
}
________________


Lister les Tickets
http
GET /tickets
Authorization: Bearer {token}
Paramètres de requête:
* status (string, optionnel) : OPEN, IN_PROGRESS, RESOLVED, CLOSED
* priority (string, optionnel)
* category (string, optionnel)
* assigned_to (uuid, optionnel)
* limit (int, optionnel, défaut=20)
Réponse:
json
{
  "total": 12,
  "items": [
    {
      "id": "880e8400-e29b-41d4-a716-446655440000",
      "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
      "priority": "HIGH",
      "status": "OPEN",
      "category": "technique",
      "assigned_to": null,
      "created_at": "2024-01-15T10:35:00Z",
      "updated_at": "2024-01-15T10:35:00Z"
    }
  ]
}
________________


Mettre à Jour un Ticket
http
PATCH /tickets/{ticket_id}
Authorization: Bearer {token}
Content-Type: application/json


{
  "status": "IN_PROGRESS",
  "assigned_to": "990e8400-e29b-41d4-a716-446655440000",
  "resolution_notes": "En cours de traitement"
}
Réponse:
json
{
  "id": "880e8400-e29b-41d4-a716-446655440000",
  "status": "IN_PROGRESS",
  "assigned_to": "990e8400-e29b-41d4-a716-446655440000",
  "resolution_notes": "En cours de traitement",
  "updated_at": "2024-01-15T11:00:00Z"
}
________________


Analytics
Obtenir les Statistiques Globales
http
GET /analytics
Authorization: Bearer {token}
Paramètres de requête:
* start_date (date, optionnel) : Format YYYY-MM-DD
* end_date (date, optionnel) : Format YYYY-MM-DD
Réponse:
json
{
  "kpis": {
    "total_conversations": 245,
    "conversations_delta": 23,
    "open_tickets": 12,
    "tickets_delta": -3,
    "resolution_rate": 87.5,
    "resolution_delta": 2.3,
    "avg_response_time": 2.8,
    "response_time_delta": -0.5
  },
  "conversations_timeline": [
    {
      "date": "2024-01-01",
      "count": 15
    },
    {
      "date": "2024-01-02",
      "count": 18
    }
  ],
  "intent_distribution": {
    "facturation": 45,
    "technique": 78,
    "forfait": 34,
    "resiliation": 12,
    "general": 76
  },
  "ticket_status": {
    "OPEN": 12,
    "IN_PROGRESS": 5,
    "RESOLVED": 156,
    "CLOSED": 145
  },
  "hourly_activity": [
    {
      "hour": 0,
      "count": 2
    },
    {
      "hour": 1,
      "count": 1
    }
  ],
  "satisfaction_score": 85.7,
  "performance": {
    "total_messages": 1245,
    "avg_resolution_time": 45.5,
    "escalation_rate": 12.5
  }
}
________________


Obtenir les Métriques de Performance
http
GET /analytics/performance
Authorization: Bearer {token}
Réponse:
json
{
  "chatbot_metrics": {
    "total_conversations": 245,
    "auto_resolved": 215,
    "escalated": 30,
    "auto_resolution_rate": 87.8,
    "avg_messages_per_conversation": 5.2,
    "avg_response_time_ms": 2800
  },
  "agent_metrics": {
    "total_agents": 5,
    "active_agents": 3,
    "avg_tickets_per_agent": 6.4,
    "avg_resolution_time_minutes": 45.5
  },
  "satisfaction_metrics": {
    "total_responses": 198,
    "avg_score": 4.3,
    "nps": 67,
    "csat": 85.7
  }
}
________________


Mastodon
Sauvegarder un Contexte
Endpoint utilisé par le Social Monitor pour sauvegarder le contexte d'un lien Mastodon.
http
POST /mastodon/save-context
Content-Type: application/json


{
  "token": "abc123def456",
  "context": {
    "mastodon_user": "user@mastodon.social",
    "mastodon_id": "123456789",
    "initial_message": "J'ai un problème avec mon réseau",
    "timestamp": "2024-01-15T10:00:00Z",
    "source": "mastodon",
    "url": "https://mastodon.social/@user/123456789"
  }
}
Réponse:
json
{
  "success": true,
  "token": "abc123def456",
  "expires_at": "2024-01-16T10:00:00Z"
}
________________


Enregistrer un Post Mastodon
http
POST /mastodon/posts
Content-Type: application/json


{
  "mastodon_id": "123456789",
  "author_username": "user@mastodon.social",
  "content": "J'ai un problème avec mon réseau #Free",
  "is_complaint": true,
  "urgency": "HIGH",
  "contact_link": "http://localhost:8501?token=abc123",
  "context_token": "abc123def456"
}
Réponse:
json
{
  "id": "aa0e8400-e29b-41d4-a716-446655440000",
  "mastodon_id": "123456789",
  "author_username": "user@mastodon.social",
  "replied": false,
  "created_at": "2024-01-15T10:00:00Z"
}
________________


AI Engine API
L'AI Engine est accessible sur http://localhost:8001
Générer une Réponse
http
POST /api/generate
Content-Type: application/json


{
  "message": "Comment configurer les APN ?",
  "conversation_history": [
    {
      "role": "user",
      "content": "Bonjour"
    },
    {
      "role": "assistant",
      "content": "Bonjour ! Comment puis-je vous aider ?"
    }
  ],
  "conversation_id": "550e8400-e29b-41d4-a716-446655440000"
}
Réponse:
json
{
  "response": "Pour configurer les APN Free Mobile : Nom: Free, APN: free...",
  "needs_escalation": false,
  "category": "technique",
  "confidence": 0.92,
  "sources": [
    {
      "type": "faq",
      "category": "technique",
      "source": "technique.json"
    }
  ]
}
________________


Ingérer des Documents
http
POST /api/ingest-documents
Réponse:
json
{
  "status": "success",
  "message": "150 documents ingérés avec succès",
  "count": 150
}
________________


Obtenir les Statistiques
http
GET /api/stats
Réponse:
json
{
  "vector_store_count": 150,
  "model_name": "mistralai/Mistral-7B-Instruct-v0.2",
  "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
  "rag_top_k": 5
}
________________


Rate Limiting
L'API implémente un rate limiting pour prévenir les abus :
* Limite générale: 100 requêtes par minute par IP
* Authentification: 5 tentatives par minute
* Chat: 20 messages par minute par utilisateur
Headers de réponse :
X-RateLimit-Limit: 100
X-RateLimit-Remaining: 95
X-RateLimit-Reset: 1642252800
Réponse en cas de dépassement:
json
{
  "detail": "Rate limit exceeded. Please try again in 45 seconds.",
  "retry_after": 45
}
________________


Codes d'Erreur
Code
	Description
	200
	OK - Requête réussie
	201
	Created - Ressource créée
	400
	Bad Request - Paramètres invalides
	401
	Unauthorized - Token manquant ou invalide
	403
	Forbidden - Accès interdit
	404
	Not Found - Ressource introuvable
	422
	Unprocessable Entity - Validation échouée
	429
	Too Many Requests - Rate limit dépassé
	500
	Internal Server Error - Erreur serveur
	Format d'erreur:
json
{
  "detail": "Description de l'erreur",
  "error_code": "ERROR_CODE",
  "timestamp": "2024-01-15T10:00:00Z"
}
________________


Webhooks
L'API peut envoyer des webhooks pour certains événements.
Configuration
http
POST /webhooks
Authorization: Bearer {token}
Content-Type: application/json


{
  "url": "https://your-domain.com/webhook",
  "events": ["ticket.created", "conversation.escalated"],
  "secret": "your_webhook_secret"
}
Événements Disponibles
* ticket.created : Nouveau ticket créé
* ticket.updated : Ticket mis à jour
* ticket.resolved : Ticket résolu
* conversation.escalated : Conversation escaladée
* mastodon.mention : Mention sur Mastodon
Payload Webhook
json
{
  "event": "ticket.created",
  "timestamp": "2024-01-15T10:00:00Z",
  "data": {
    "ticket_id": "880e8400-e29b-41d4-a716-446655440000",
    "priority": "HIGH",
    "category": "technique"
  },
  "signature": "sha256=..."
}
________________


Exemples de Code
Python (requests)
python
import requests


BASE_URL = "http://localhost:8000/api/v1"


# Authentification
response = requests.post(
    f"{BASE_URL}/auth/login",
    json={
        "username": "user@example.com",
        "password": "password"
    }
)
token = response.json()["access_token"]


# Envoyer un message
headers = {"Authorization": f"Bearer {token}"}
response = requests.post(
    f"{BASE_URL}/chat/message",
    headers=headers,
    json={
        "message": "Comment consulter ma facture ?",
        "user_info": {
            "full_name": "Jean Dupont",
            "phone_number": "0612345678"
        }
    }
)


print(response.json())
JavaScript (fetch)
javascript
const BASE_URL = "http://localhost:8000/api/v1";


// Authentification
const loginResponse = await fetch(`${BASE_URL}/auth/login`, {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({
    username: "user@example.com",
    password: "password"
  })
});
const { access_token } = await loginResponse.json();


// Envoyer un message
const chatResponse = await fetch(`${BASE_URL}/chat/message`, {
  method: "POST",
  headers: {
    "Content-Type": "application/json",
    "Authorization": `Bearer ${access_token}`
  },
  body: JSON.stringify({
    message: "Comment consulter ma facture ?",
    user_info: {
      full_name: "Jean Dupont",
      phone_number: "0612345678"
    }
  })
});


const data = await chatResponse.json();
console.log(data);
cURL
bash
# Authentification
TOKEN=$(curl -X POST "http://localhost:8000/api/v1/auth/login" \
  -H "Content-Type: application/json" \
  -d '{"username":"user@example.com","password":"password"}' \
  | jq -r '.access_token')


# Envoyer un message
curl -X POST "http://localhost:8000/api/v1/chat/message" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Comment consulter ma facture ?",
    "user_info": {
      "full_name": "Jean Dupont",
      "phone_number": "0612345678"
    }
  }'
________________


Support
Pour toute question sur l'API :
* Documentation interactive : http://localhost:8000/docs
* Issues GitHub : https://github.com/votre-username/chatbot-free-mobile/issues
* Email : api-support@votre-domaine.com


---


